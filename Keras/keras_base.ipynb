{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras的模块\n",
    "[参考](http://www.tensorflownews.com/2018/03/15/%E4%BD%BF%E7%94%A8keras%E8%BF%9B%E8%A1%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%9A%EF%BC%88%E4%B8%80%EF%BC%89keras-%E5%85%A5%E9%97%A8/)  \n",
    "默认tensorflow后台\n",
    "<img src=\"image/Keras.jpg\"  width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1全连接层：神经网络中最常用到的，实现对神经网络里的神经元激活。  \n",
    "**Dense（units, activation=’relu’, use_bias=True）**  \n",
    "参数说明：\n",
    "- units: 全连接层输出的维度，即下一层神经元的个数。\n",
    "- activation：激活函数，默认使用Relu。\n",
    "- use_bias：是否使用bias偏置项。\n",
    "\n",
    "1.2激活层：对上一层的输出应用激活函数。  \n",
    "**Activation(activation)**  \n",
    "参数说明：\n",
    "- activation：想要使用的激活函数，如：’relu’、’tanh’、‘sigmoid’等。\n",
    "\n",
    "1.3Dropout层：对上一层的神经元随机选取一定比例的失活，不更新，但是权重仍然保留，防止过拟合。  \n",
    "**Dropout(rate)**  \n",
    "参数说明:\n",
    "- rate：失活的比例，0-1的浮点数。\n",
    "\n",
    "1.4Flatten层：将一个维度大于或等于3的高维矩阵，“压扁”为一个二维矩阵。即保留第一个维度（如：batch的个数），然后将剩下维度的值相乘作为“压扁”矩阵的第二个维度。  \n",
    "**Flatten()**\n",
    "\n",
    "1.5Reshape层：该层的作用和reshape一样，就是将输入的维度重构成特定的shape。\n",
    "**Reshape(target_shape)**  \n",
    "参数说明：\n",
    "- target_shape：目标矩阵的维度，不包含batch样本数。  \n",
    "\n",
    "如我们想要一个9个元素的输入向量重构成一个(None, 3, 3)的二维矩阵：\n",
    "`Reshape((3,3), input_length=(16, ))`\n",
    "\n",
    "1.6卷积层：卷积操作分为一维、二维、三维，分别为Conv1D、Conv2D、Conv3D。一维卷积主要应用于以时间序列数据或文本数据，二维卷积通常应用于图像数据。由于这三种的使用和参数都基本相同，所以主要以处理图像数据的Conv2D进行说明。  \n",
    "**Conv2D(filters, kernel_size, strides=(1, 1), padding=’valid’)**  \n",
    "参数说明：\n",
    "- filters：卷积核的个数。\n",
    "- kernel_size：卷积核的大小。\n",
    "- strdes：步长，二维中默认为(1, 1)，一维默认为1。\n",
    "- padding：补“0”策略，’valid‘指卷积后的大小与原来的大小可以不同，’same‘则卷积后大小与原来大小一致。\n",
    "\n",
    " \n",
    "1.7池化层：与卷积层一样，最大统计量池化和平均统计量池化也有三种，分别为MaxPooling1D、MaxPooling2D、MaxPooling3D和AveragePooling1D、AveragePooling2D、AveragePooling3D，由于使用和参数基本相同，所以主要以MaxPooling2D进行说明。  \n",
    "**MaxPooling(pool_size=(2,2), strides=None, padding=’valid’)**  \n",
    "参数说明：\n",
    "- pool_size：长度为2的整数tuple，表示在横向和纵向的下采样样子，一维则为纵向的下采样因子。\n",
    "- padding：和卷积层的padding一样。\n",
    "\n",
    "1.8循环层：循环神经网络中的RNN、LSTM和GRU都继承本层，所以该父类的参数同样使用于对应的子类SimpleRNN、LSTM和GRU。  \n",
    "**Recurrent(return_sequences=False)**  \n",
    "- return_sequences：控制返回的类型，“False”返回输出序列的最后一个输出，“True”则返回整个序列。当我们要搭建多层神经网络（如深层LSTM）时，若不是最后一层，则需要将该参数设为True。\n",
    "\n",
    " \n",
    "1.9嵌入层：该层只能用在模型的第一层，是将所有索引标号的稀疏矩阵映射到致密的低维矩阵。如我们对文本数据进行处理时，对每个词编号后，我们希望将词编号变成词向量就可以使用嵌入层。  \n",
    "**Embedding(input_dim, output_dim, input_length)**  \n",
    "参数说明：\n",
    "- Input_dim：大于或等于0的整数，字典的长度即输入数据的个数。\n",
    "- output_dim：输出的维度，如词向量的维度。\n",
    "- input_length：当输入序列的长度为固定时为该长度，然后要在该层后加上Flatten层，然后再加上\n",
    "- Dense层，则必须指定该参数，否则Dense层无法自动推断输出的维度。\n",
    "\n",
    "该层可能有点费解，举个例子，当我们有一个文本，该文本有100句话，我们已经通过一系列操作，使得文本变成一个(100,32)矩阵，每行代表一句话，每个元素代表一个词，我们希望将该词变为64维的词向量：`Embedding(100, 64, input_length=32)`  \n",
    "则输出的矩阵的shape变为(100, 32, 64)：即每个词已经变成一个64维的词向量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型优化和训练  \n",
    "**compile(optimizer, loss, metrics=None)**  \n",
    "参数说明：\n",
    "- optimizer：优化器，如：’SGD‘，’Adam‘等。\n",
    "- loss：定义模型的损失函数，如：’mse’，’mae‘等。\n",
    "- metric：模型的评价指标，如：’accuracy‘等。\n",
    "\n",
    "**fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, validation_split=0.0)**  \n",
    "参数说明：\n",
    "- x：输入数据。\n",
    "- y：标签。\n",
    "- batch_size：梯度下降时每个batch包含的样本数。\n",
    "- epochs：整数，所有样本的训练次数。\n",
    "- verbose：日志显示，0为不显示，1为显示进度条记录，2为每个epochs输出一行记录。\n",
    "- validation_split：0-1的浮点数，切割输入数据的一定比例作为验证集。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两层神经网络的实现\n",
    "<img src=\"image/2layersNN.jpg\"  width=\"400\" >\n",
    "两层神经网络:  \n",
    "输入层为784个神经元，  \n",
    "隐藏层为32个神经元，  \n",
    "输出层为10个神经元，  \n",
    "隐藏层使用relu激活函数  \n",
    "输出层使用softmax激活函数  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用序列模型\n",
    "使用序列模型，首先要实例化Sequential类，之后使用该类的add函数加入想要的每一层，从而实现模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=32, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用通用模型\n",
    "使用通用模型，首先要使用Input函数将输入转化为一个tensor，然后将每一层用变量存储后，作为下一层的参数，最后使用Model类将输入和输出作为参数即可搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = Input(shape=(784,))  #将输入变成张量\n",
    "dense_1 = Dense(units=32)(x_input)\n",
    "act_1 = Activation('relu')(dense_1)\n",
    "output = Dense(units=10, activation='softmax')(act_1)\n",
    "model = Model(inputs=x_input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的优化和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',loss='mse',metrics=['accuracy'])\n",
    "model.fit(x, y, batch_size=64, epochs=3, validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
