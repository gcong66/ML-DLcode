{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单层RNN\n",
    "<img src=\"image/SimpleRNN.jpg\"  width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 具体的前向传播计算过程如下：\n",
    "<img src=\"image/forward.png\"  width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 双向RNN(BRNN)\n",
    "双向RNN需要保存两个方向的权重矩阵，所以需要的内存约为RNN的两倍\n",
    "<img src=\"image/BiRNN.jpg\"  width=\"300\" >\n",
    "<img src=\"image/formula.png\"  width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层双向RNN(DBRNN)  \n",
    "当信息量太大的时候一次性保存不下所有重要信息，通过多个隐藏层可以保存更多的重要信息，正如我们看电视剧的时候也可能重复看同一集记住更多关键剧情\n",
    "<img src=\"image/DBRNN.png\"  width=\"300\" >\n",
    "注：  \n",
    "每一层循环体中参数是共享的，但是不同层之间的权重矩阵是不同的。  \n",
    "纵向有dropout，横向无dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras在layers包的recurrent模块中实现了RNN相关层模型的支持，并在wrapper模型中实现双向RNN包装器。  \n",
    "recurrent模块中的RNN模型包括RNN、LSTM、GRU等模型：\n",
    "\n",
    "1.RNN：全连接RNN模型\n",
    "\n",
    "**SimpleRNN(units,activation=’tanh’,dropout=0.0,recurrent_dropout=0.0, return_sequences=False)**\n",
    "\n",
    "2.LSTM：长短记忆模型\n",
    "\n",
    "**LSTM(units,activation=’tanh’,dropout=0.0,recurrent_dropout=0.0,return_sequences=False)**\n",
    "\n",
    "3.GRU：门限循环单元\n",
    "\n",
    "**GRU(units,activation=’tanh’,dropout=0.0,recurrent_dropout=0.0,return_sequences=False)**\n",
    "\n",
    "4.参数说明：\n",
    "\n",
    "- units: RNN输出的维度\n",
    "\n",
    "- activation: 激活函数，默认为tanh\n",
    "\n",
    "- dropout: 0~1之间的浮点数，控制输入线性变换的神经元失活的比例\n",
    "\n",
    "- recurrent_dropout：0~1之间的浮点数，控制循环状态的线性变换的神经元失活比例\n",
    "\n",
    "- return_sequences: True返回整个序列,用于stack两个层，False返回输出序列的最后一个输出，若模型为深层模型时设为True\n",
    "\n",
    "- input_dim: 当使用该层为模型首层时，应指定该值\n",
    "\n",
    "- input_length: 当输入序列的长度固定时，该参数为输入序列的长度。当需要在该层后连接Flatten层，然后又要连接Dense层时，需要指定该参数  \n",
    "\n",
    "wrapper模块实现双向RNN模型：\n",
    "\n",
    "双向RNN包装器  \n",
    "**Bidirectional(layer, merge_mode=’concat’, weights=None)**\n",
    "\n",
    "参数说明:\n",
    "\n",
    "- layer: SimpleRNN、LSTM、GRU等模型结构，确定是哪种RNN的双向模型  \n",
    "\n",
    "- Merge_mode: 前向和后向RNN输出的结合方式，为sum,mul,concat,ave和None之一，若为None，则不结合，以列表形式返回，若是上文说到的拼接则为concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Imdb数据集进行情感分析(二分类)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据\n",
    "数据清洗：去除含有html标签的  \n",
    "分词：此处为英文,不需  \n",
    "去停用词：可以去除”the”、”a”等词,此处没加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def rm_tags(text):\n",
    "    re_tag = re.compile(r'<[^>]+>')\n",
    "    return re_tag.sub('', text)\n",
    "\n",
    "def read_files(filetype):\n",
    "    \"\"\"\n",
    "    filetype: 'train' or 'test'\n",
    "    return:\n",
    "    all_texts: filetype数据集文本\n",
    "    all_labels: filetype数据集标签\n",
    "    \"\"\"\n",
    "    # 标签1表示正面，0表示负面\n",
    "    all_labels = [1]*12500 + [0]*12500\n",
    "    all_texts = []\n",
    "    file_list = []\n",
    "    path = r'./data/aclImdb/'\n",
    "    # 读取正面文本名\n",
    "    pos_path = path + filetype + '/pos/'\n",
    "    for file in os.listdir(pos_path):\n",
    "        file_list.append(pos_path+file)\n",
    "    # 读取负面文本名\n",
    "    neg_path = path + filetype + '/neg/'\n",
    "    for file in os.listdir(neg_path):\n",
    "        file_list.append(neg_path+file)\n",
    "    # 将所有文本内容加到all_texts\n",
    "    for file_name in file_list:\n",
    "        with open(file_name, encoding='utf-8') as f:\n",
    "            all_texts.append(rm_tags(\" \".join(f.readlines())))\n",
    "    return all_texts, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已解压过了\n",
    "# tfile = tarfile.open(r'./data/aclImdb_v1.tar.gz', 'r:gz')  # r;gz是读取gzip压缩文件\n",
    "# result = tfile.extractall('./data/')  # 解压缩文件到data文件夹中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = read_files('train')\n",
    "test_texts, test_labels = read_files('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理成深度学习需要的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(train_texts, train_labels, test_texts, test_labels):\n",
    "    tokenizer = Tokenizer(num_words=3800)  \n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "    # 对每一句影评文字转换为数字列表，使用每个词的编号进行编号\n",
    "    x_train_seq = tokenizer.texts_to_sequences(train_texts)\n",
    "    x_test_seq = tokenizer.texts_to_sequences(test_texts)\n",
    "    x_train = sequence.pad_sequences(x_train_seq, maxlen=380)\n",
    "    x_test = sequence.pad_sequences(x_test_seq, maxlen=380)\n",
    "    y_train = np.array(train_labels)\n",
    "    y_test = np.array(test_labels)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = preprocessing(train_texts, train_labels, test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN模型\n",
    "Embedding + RNN + FC1 + sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(maxlen = 380, max_features = 3800, embed_size = 32):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(SimpleRNN(16))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary()：可以查看模型结构和参数等信息，便于理解模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 126,993\n",
      "Trainable params: 126,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiRNN模型\n",
    "Embedding + BiRNN + Flatten + sigmoid  \n",
    "使用wrappers包的Bidirecitional模块实现双向RNN模型，并且要将return_sequences参数设置为True,因为如上文所述需要将前、后向的重要信息拼接起来，所以需要将整个序列返回，而不是只返回最后一个预测词。\n",
    "\n",
    "并且上文提到的是将前后向的进行拼接，所以使用的是’concat’，也可以使用sum对前后向结果求和或者其他对结果进行相应的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BRNN(maxlen = 380, max_features = 3800, embed_size = 32):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(SimpleRNN(16, return_sequences=True), merge_mode='concat'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 380, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12160)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 12161     \n",
      "=================================================================\n",
      "Total params: 135,329\n",
      "Trainable params: 135,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BRNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBRNN\n",
    "Embedding + BiRNN + BiRNN + sigmoid  \n",
    "搭建一个两层的DBRNN模型，只需要再加一层SimpleRNN即可。  \n",
    "要注意的是，如果要搭建多层DBRNN模型，除了最后一层SimpleRNN外，其他的SimpleRNN层都需要将return_sequences参数设置为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBRNN(maxlen = 380, max_features = 3800, embed_size = 32):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(SimpleRNN(16, return_sequences=True), merge_mode='concat'))\n",
    "    model.add(SimpleRNN(8))  #默认return_sequences=False\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 380, 32)           1568      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 123,505\n",
      "Trainable params: 123,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DBRNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入EarlyStopping，当验证集准确率不再改善时停止训练\n",
    "之所以要提前停止训练，是因为继续训练会导致测试集上的准确率下降。那继续训练导致测试准确率下降的原因可能是  \n",
    "1. 过拟合  \n",
    "2. 学习率过大导致不收敛   \n",
    "3. 使用正则项的时候，Loss的减少可能不是因为准确率增加导致的，而是因为权重大小的降低\n",
    "\n",
    "在model.fit函数中调用callbacks，fit函数中有一个参数为callbacks。注意这里需要输入的是list类型的数据，所以通常情况只用EarlyStopping的话也要是[EarlyStopping()]\n",
    "\n",
    "keras.callbacks.EarlyStopping(monitor=’val_loss’, patience=0, verbose=0, mode=’auto’)\n",
    "\n",
    "参数说明：\n",
    "\n",
    "monitor：需要监视的量，如’val_loss’, ‘val_acc’, ‘acc’, ‘loss’。\n",
    "\n",
    "patience：能够容忍多少个epoch内都没有improvement。\n",
    "\n",
    "verbose：信息展示模式\n",
    "\n",
    "mode：‘auto’，‘min’，‘max’之一，在min模式下，如果检测值停止下降则中止训练。在max模式下，当检测值不再上升则停止训练。例如，当监测值为val_acc时，模式应为max，当检测值为val_loss时，模式应为min。在auto模式下，评价准则由被监测值的名字自动推断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_acc', patience=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "22500/22500 [==============================] - 40s 2ms/step - loss: 0.5688 - acc: 0.6891 - val_loss: 0.6299 - val_acc: 0.7252\n",
      "Epoch 2/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.3803 - acc: 0.8403 - val_loss: 0.4498 - val_acc: 0.7872\n",
      "Epoch 3/20\n",
      "22500/22500 [==============================] - 38s 2ms/step - loss: 0.3136 - acc: 0.8740 - val_loss: 0.4739 - val_acc: 0.7932\n",
      "Epoch 4/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.2816 - acc: 0.8897 - val_loss: 0.4577 - val_acc: 0.8280\n",
      "Epoch 5/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.2666 - acc: 0.8949 - val_loss: 0.5026 - val_acc: 0.8036\n",
      "Epoch 6/20\n",
      "22500/22500 [==============================] - 38s 2ms/step - loss: 0.2432 - acc: 0.9075 - val_loss: 1.2519 - val_acc: 0.5892\n",
      "Epoch 7/20\n",
      "22500/22500 [==============================] - 38s 2ms/step - loss: 0.2384 - acc: 0.9080 - val_loss: 0.3034 - val_acc: 0.8780\n",
      "Epoch 8/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.2101 - acc: 0.9199 - val_loss: 0.3785 - val_acc: 0.8524\n",
      "Epoch 9/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.2001 - acc: 0.9234 - val_loss: 0.5251 - val_acc: 0.7920\n",
      "Epoch 10/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.1918 - acc: 0.9259 - val_loss: 0.4207 - val_acc: 0.8532\n",
      "Epoch 11/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.1737 - acc: 0.9352 - val_loss: 0.4903 - val_acc: 0.8484\n",
      "Epoch 12/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.1674 - acc: 0.9370 - val_loss: 0.6509 - val_acc: 0.7824\n",
      "Epoch 13/20\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.1510 - acc: 0.9432 - val_loss: 0.3893 - val_acc: 0.8872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9c41a39b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练BiRNN模型\n",
    "需要重启kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "22500/22500 [==============================] - 61s 3ms/step - loss: 0.5326 - acc: 0.7066 - val_loss: 0.5931 - val_acc: 0.7208\n",
      "Epoch 2/20\n",
      "22500/22500 [==============================] - 58s 3ms/step - loss: 0.2934 - acc: 0.8772 - val_loss: 0.1639 - val_acc: 0.9352\n",
      "Epoch 3/20\n",
      "22500/22500 [==============================] - 58s 3ms/step - loss: 0.2482 - acc: 0.8981 - val_loss: 0.3986 - val_acc: 0.8272\n",
      "Epoch 4/20\n",
      "22500/22500 [==============================] - 58s 3ms/step - loss: 0.2112 - acc: 0.9160 - val_loss: 0.3555 - val_acc: 0.8448\n",
      "Epoch 5/20\n",
      "22500/22500 [==============================] - 58s 3ms/step - loss: 0.1740 - acc: 0.9311 - val_loss: 0.3566 - val_acc: 0.8644\n",
      "Epoch 6/20\n",
      "22500/22500 [==============================] - 57s 3ms/step - loss: 0.1498 - acc: 0.9420 - val_loss: 0.6625 - val_acc: 0.7496\n",
      "Epoch 7/20\n",
      "22500/22500 [==============================] - 58s 3ms/step - loss: 0.1309 - acc: 0.9486 - val_loss: 0.3403 - val_acc: 0.8668\n",
      "Epoch 8/20\n",
      "22500/22500 [==============================] - 58s 3ms/step - loss: 0.1075 - acc: 0.9587 - val_loss: 0.3986 - val_acc: 0.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29382254748>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练DBRNN模型\n",
    "需要重启kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "22500/22500 [==============================] - 96s 4ms/step - loss: 0.6199 - acc: 0.6528 - val_loss: 0.7662 - val_acc: 0.5628\n",
      "Epoch 2/20\n",
      "22500/22500 [==============================] - 91s 4ms/step - loss: 0.4370 - acc: 0.8238 - val_loss: 0.4569 - val_acc: 0.8084\n",
      "Epoch 3/20\n",
      "22500/22500 [==============================] - 91s 4ms/step - loss: 0.3731 - acc: 0.8615 - val_loss: 0.4375 - val_acc: 0.8108\n",
      "Epoch 4/20\n",
      "22500/22500 [==============================] - 92s 4ms/step - loss: 0.3367 - acc: 0.8758 - val_loss: 0.3261 - val_acc: 0.8696\n",
      "Epoch 5/20\n",
      "22500/22500 [==============================] - 91s 4ms/step - loss: 0.3245 - acc: 0.8793 - val_loss: 0.4073 - val_acc: 0.8372\n",
      "Epoch 6/20\n",
      "22500/22500 [==============================] - 91s 4ms/step - loss: 0.2901 - acc: 0.8956 - val_loss: 0.4754 - val_acc: 0.8164\n",
      "Epoch 7/20\n",
      "22500/22500 [==============================] - 91s 4ms/step - loss: 0.2873 - acc: 0.8961 - val_loss: 0.4962 - val_acc: 0.8072\n",
      "Epoch 8/20\n",
      "22500/22500 [==============================] - 92s 4ms/step - loss: 0.2519 - acc: 0.9135 - val_loss: 0.4592 - val_acc: 0.8248\n",
      "Epoch 9/20\n",
      "22500/22500 [==============================] - 92s 4ms/step - loss: 0.2311 - acc: 0.9215 - val_loss: 0.6726 - val_acc: 0.7608\n",
      "Epoch 10/20\n",
      "22500/22500 [==============================] - 93s 4ms/step - loss: 0.2179 - acc: 0.9261 - val_loss: 0.4690 - val_acc: 0.8220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d4472be48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 184s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN:test_loss: 0.465460, accuracy: 0.859240\n"
     ]
    }
   ],
   "source": [
    "print('RNN:test_loss: %f, accuracy: %f' % (scores[0], scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRNN:test_loss: 0.391547, accuracy: 0.866680\n"
     ]
    }
   ],
   "source": [
    "print('BRNN:test_loss: %f, accuracy: %f' % (scores[0], scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBRNN:test_loss: 0.385426, accuracy: 0.857360\n"
     ]
    }
   ],
   "source": [
    "print('DBRNN:test_loss: %f, accuracy: %f' % (scores[0], scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
