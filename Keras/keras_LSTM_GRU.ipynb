{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "<img src=\"image/LSTM.png\"  width=\"660\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遗忘门\n",
    "决定什么信息被丢弃\n",
    "<img src=\"image/LstmForgetGate.png\"  width=\"660\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入门\n",
    "决定什么值被更新  \n",
    "创建一个新的候选向量\n",
    "<img src=\"image/LstmInputGate.png\"  width=\"660\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出门\n",
    "决定细胞状态的哪部分会被输出\n",
    "<img src=\"image/LstmOutputGate.png\"  width=\"660\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 细胞状态更新\n",
    "<img src=\"image/LstmCellUpdate.png\"  width=\"660\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 双向LSTM（Bi-directional LSTM）\n",
    "<img src=\"image/BiLSTM.png\"  width=\"600\" >\n",
    "在Forward层从1时刻到t时刻正向计算一遍，得到并保存每个时刻向前隐含层的输出。  \n",
    "在Backward层沿着时刻t到时刻1反向计算一遍，得到并保存每个时刻向后隐含层的输出。  \n",
    "在每个时刻结合Forward层和Backward层的相应时刻输出的结果得到最终的输出:\n",
    "<img src=\"image/BILSTM-formula.png\" width=\"300\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "GRU只有两个门结构：更新门和重置门，分别为图中的z_t和r_t\n",
    "<img src=\"image/GRU.png\"  width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Imdb数据集进行情感分析(二分类)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据\n",
    "数据清洗：去除含有html标签的  \n",
    "分词：此处为英文,不需  \n",
    "去停用词：可以去除”the”、”a”等词,此处没加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def rm_tags(text):\n",
    "    re_tag = re.compile(r'<[^>]+>')\n",
    "    return re_tag.sub('', text)\n",
    "\n",
    "def read_files(filetype):\n",
    "    \"\"\"\n",
    "    filetype: 'train' or 'test'\n",
    "    return:\n",
    "    all_texts: filetype数据集文本\n",
    "    all_labels: filetype数据集标签\n",
    "    \"\"\"\n",
    "    # 标签1表示正面，0表示负面\n",
    "    all_labels = [1]*12500 + [0]*12500\n",
    "    all_texts = []\n",
    "    file_list = []\n",
    "    path = r'./data/aclImdb/'\n",
    "    # 读取正面文本名\n",
    "    pos_path = path + filetype + '/pos/'\n",
    "    for file in os.listdir(pos_path):\n",
    "        file_list.append(pos_path+file)\n",
    "    # 读取负面文本名\n",
    "    neg_path = path + filetype + '/neg/'\n",
    "    for file in os.listdir(neg_path):\n",
    "        file_list.append(neg_path+file)\n",
    "    # 将所有文本内容加到all_texts\n",
    "    for file_name in file_list:\n",
    "        with open(file_name, encoding='utf-8') as f:\n",
    "            all_texts.append(rm_tags(\" \".join(f.readlines())))\n",
    "    return all_texts, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = read_files('train')\n",
    "test_texts, test_labels = read_files('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理成深度学习需要的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(train_texts, train_labels, test_texts, test_labels):\n",
    "    tokenizer = Tokenizer(num_words=3800)  \n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "    # 对每一句影评文字转换为数字列表，使用每个词的编号进行编号\n",
    "    x_train_seq = tokenizer.texts_to_sequences(train_texts)\n",
    "    x_test_seq = tokenizer.texts_to_sequences(test_texts)\n",
    "    x_train = sequence.pad_sequences(x_train_seq, maxlen=380)\n",
    "    x_test = sequence.pad_sequences(x_test_seq, maxlen=380)\n",
    "    y_train = np.array(train_labels)\n",
    "    y_test = np.array(test_labels)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = preprocessing(train_texts, train_labels, test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM模型\n",
    "Embedding + LSTM + FC1 +sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(3800, 32, input_length=380))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-LSTM模型\n",
    "Embedding + BiLSTM + Flatten +sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(3800, 32, input_length=380)) # max_features = 3800, embed_size = 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True), merge_mode='concat'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU模型\n",
    "Embedding + GRU +  FC1 +sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(3800, 32, input_length=380))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_acc', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "22500/22500 [==============================] - 57s 3ms/step - loss: 0.5602 - acc: 0.6881 - val_loss: 0.3648 - val_acc: 0.8320\n",
      "Epoch 2/20\n",
      "22500/22500 [==============================] - 52s 2ms/step - loss: 0.2848 - acc: 0.8835 - val_loss: 0.3267 - val_acc: 0.8604\n",
      "Epoch 3/20\n",
      "22500/22500 [==============================] - 53s 2ms/step - loss: 0.2308 - acc: 0.9101 - val_loss: 0.3918 - val_acc: 0.8416\n",
      "Epoch 4/20\n",
      "22500/22500 [==============================] - 54s 2ms/step - loss: 0.2101 - acc: 0.9191 - val_loss: 0.2892 - val_acc: 0.8800\n",
      "Epoch 5/20\n",
      "22500/22500 [==============================] - 54s 2ms/step - loss: 0.1957 - acc: 0.9271 - val_loss: 0.5046 - val_acc: 0.8064\n",
      "Epoch 6/20\n",
      "22500/22500 [==============================] - 53s 2ms/step - loss: 0.1934 - acc: 0.9259 - val_loss: 0.2508 - val_acc: 0.8976\n",
      "Epoch 7/20\n",
      "22500/22500 [==============================] - 54s 2ms/step - loss: 0.1725 - acc: 0.9366 - val_loss: 0.3242 - val_acc: 0.8728\n",
      "Epoch 8/20\n",
      "22500/22500 [==============================] - 54s 2ms/step - loss: 0.1607 - acc: 0.9420 - val_loss: 0.4565 - val_acc: 0.8192\n",
      "Epoch 9/20\n",
      "22500/22500 [==============================] - 54s 2ms/step - loss: 0.1449 - acc: 0.9471 - val_loss: 0.4313 - val_acc: 0.8384\n",
      "Epoch 10/20\n",
      "22500/22500 [==============================] - 54s 2ms/step - loss: 0.1296 - acc: 0.9549 - val_loss: 0.6646 - val_acc: 0.7928\n",
      "Epoch 11/20\n",
      "22500/22500 [==============================] - 54s 2ms/step - loss: 0.1280 - acc: 0.9552 - val_loss: 0.4145 - val_acc: 0.8572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26fe567ac88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 20\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练bi-LSTM\n",
    "重启核Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "22500/22500 [==============================] - 91s 4ms/step - loss: 0.5233 - acc: 0.7145 - val_loss: 0.3469 - val_acc: 0.8528\n",
      "Epoch 2/20\n",
      "22500/22500 [==============================] - 85s 4ms/step - loss: 0.2863 - acc: 0.8816 - val_loss: 0.3176 - val_acc: 0.8600\n",
      "Epoch 3/20\n",
      "22500/22500 [==============================] - 86s 4ms/step - loss: 0.2389 - acc: 0.9044 - val_loss: 0.2502 - val_acc: 0.8908\n",
      "Epoch 4/20\n",
      "22500/22500 [==============================] - 85s 4ms/step - loss: 0.2248 - acc: 0.9097 - val_loss: 0.1778 - val_acc: 0.9264\n",
      "Epoch 5/20\n",
      "22500/22500 [==============================] - 85s 4ms/step - loss: 0.2043 - acc: 0.9212 - val_loss: 0.4141 - val_acc: 0.8224\n",
      "Epoch 6/20\n",
      "22500/22500 [==============================] - 85s 4ms/step - loss: 0.1866 - acc: 0.9288 - val_loss: 0.3829 - val_acc: 0.8372\n",
      "Epoch 7/20\n",
      "22500/22500 [==============================] - 85s 4ms/step - loss: 0.1784 - acc: 0.9287 - val_loss: 0.4734 - val_acc: 0.8100\n",
      "Epoch 8/20\n",
      "22500/22500 [==============================] - 86s 4ms/step - loss: 0.1657 - acc: 0.9357 - val_loss: 0.3825 - val_acc: 0.8488\n",
      "Epoch 9/20\n",
      "22500/22500 [==============================] - 87s 4ms/step - loss: 0.1566 - acc: 0.9393 - val_loss: 0.3335 - val_acc: 0.8660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a743334a20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 20\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练GRU\n",
    "重启核Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/20\n",
      "22500/22500 [==============================] - 48s 2ms/step - loss: 0.5995 - acc: 0.6503 - val_loss: 0.3375 - val_acc: 0.8580\n",
      "Epoch 2/20\n",
      "22500/22500 [==============================] - 45s 2ms/step - loss: 0.3097 - acc: 0.8697 - val_loss: 0.2552 - val_acc: 0.8928\n",
      "Epoch 3/20\n",
      "22500/22500 [==============================] - 45s 2ms/step - loss: 0.2470 - acc: 0.9023 - val_loss: 0.3490 - val_acc: 0.8624\n",
      "Epoch 4/20\n",
      "22500/22500 [==============================] - 45s 2ms/step - loss: 0.2212 - acc: 0.9160 - val_loss: 0.3074 - val_acc: 0.8776\n",
      "Epoch 5/20\n",
      "22500/22500 [==============================] - 45s 2ms/step - loss: 0.2019 - acc: 0.9242 - val_loss: 0.2951 - val_acc: 0.8744\n",
      "Epoch 6/20\n",
      "22500/22500 [==============================] - 45s 2ms/step - loss: 0.1986 - acc: 0.9244 - val_loss: 0.2979 - val_acc: 0.8828\n",
      "Epoch 7/20\n",
      "22500/22500 [==============================] - 45s 2ms/step - loss: 0.1812 - acc: 0.9329 - val_loss: 0.3063 - val_acc: 0.8820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a92a48ba8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 20\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 136s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:test_loss: 0.400232, accuracy: 0.862680\n"
     ]
    }
   ],
   "source": [
    "print('LSTM:test_loss: %f, accuracy: %f' % (scores[0], scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-LSTM:test_loss: 0.332111, accuracy: 0.870680\n"
     ]
    }
   ],
   "source": [
    "print('Bi-LSTM:test_loss: %f, accuracy: %f' % (scores[0], scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU:test_loss: 0.328848, accuracy: 0.869520\n"
     ]
    }
   ],
   "source": [
    "print('GRU:test_loss: %f, accuracy: %f' % (scores[0], scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
