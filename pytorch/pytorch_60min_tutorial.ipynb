{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch张量的创建和操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 生成空张量\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9134, 0.4983, 0.4828],\n",
      "        [0.9517, 0.4816, 0.6796],\n",
      "        [0.8687, 0.7801, 0.5605],\n",
      "        [0.3573, 0.2398, 0.6629],\n",
      "        [0.7966, 0.9700, 0.2082]])\n"
     ]
    }
   ],
   "source": [
    "# 生成随机张量\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 生成全0张量\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# python列表转化为pytorch的tensor\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.9550, -1.4400,  0.9242],\n",
      "        [-0.4318, -1.2278, -0.4229],\n",
      "        [-0.5276,  0.0289, -0.5014],\n",
      "        [-0.6549, -1.5193, -1.0159],\n",
      "        [-0.9128,  0.2373, -0.0552]])\n"
     ]
    }
   ],
   "source": [
    "# 或者根据现有的张量创建张量。重用张量的shape和dtype\n",
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 获取尺寸\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8180, -0.5913,  1.1825],\n",
      "        [ 0.3996, -0.6948, -0.4156],\n",
      "        [ 0.4656,  0.1832,  0.4380],\n",
      "        [-0.3849, -0.8290, -0.1429],\n",
      "        [-0.6269,  0.7232,  0.8511]])\n",
      "tensor([[ 1.8180, -0.5913,  1.1825],\n",
      "        [ 0.3996, -0.6948, -0.4156],\n",
      "        [ 0.4656,  0.1832,  0.4380],\n",
      "        [-0.3849, -0.8290, -0.1429],\n",
      "        [-0.6269,  0.7232,  0.8511]])\n"
     ]
    }
   ],
   "source": [
    "# 加法有2种方式\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "# -------------------\n",
    "print(torch.add(x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8180, -0.5913,  1.1825],\n",
      "        [ 0.3996, -0.6948, -0.4156],\n",
      "        [ 0.4656,  0.1832,  0.4380],\n",
      "        [-0.3849, -0.8290, -0.1429],\n",
      "        [-0.6269,  0.7232,  0.8511]])\n"
     ]
    }
   ],
   "source": [
    "# torch.add提供输出张量作为参数\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8180, -0.5913,  1.1825],\n",
      "        [ 0.3996, -0.6948, -0.4156],\n",
      "        [ 0.4656,  0.1832,  0.4380],\n",
      "        [-0.3849, -0.8290, -0.1429],\n",
      "        [-0.6269,  0.7232,  0.8511]])\n"
     ]
    }
   ],
   "source": [
    "# .add_ 内部加\n",
    "# 任何直接在原张量内部操作都是用_后固定。x.copy_(y), x.t_()\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4400, -1.2278,  0.0289, -1.5193,  0.2373])\n"
     ]
    }
   ],
   "source": [
    "# numpy切片查询\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# 改变tensor的形状，如tensorflow的reshape\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5084])\n",
      "0.5083978176116943\n"
     ]
    }
   ],
   "source": [
    "# 如果张量中只有一个元素，使用.item（）将值转化为Python数字\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 和numpy的互换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Torch Tensor==>numpy数组: .numpy()\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(a))\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Torch Tensor的值在内部改变了，对应转成numpy的b的值也变了\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy数组==>Torch Tensor: .from_numpy()\n",
    "# numpy里的值改变了，对应映射的Torch Tensor值也动态改变了\n",
    "import numpy as np\n",
    "a = np.ones(5) #[1,1,1,1,1]\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了CharTensor之外，所有在CPU上的Tensors都支持和NumPy互转"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5084], device='cuda:0')\n",
      "tensor([1.5084], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 可以使用.to方法将张量移动到任何设备上\n",
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # 直接在GPU上创建张量，或用`.to(\"cuda\")``从CPU移到GPU上\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` 把z从GPU移到CPU上,同时也可以改变dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autograd: 自动微分\n",
    "PyTorch中所有神经网络的核心是autograd包。 让我们首先简要地访问它，然后我们将去训练我们的第一个神经网络。\n",
    "\n",
    "autograd软件包为Tensors上的所有操作提供自动微分。 它是一个运行时定义的框架，这意味着backprop由您的代码运行方式来定义，并且每个迭代都可以不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Tensor是包的核心类。如果将其属性.requires_grad设置为True，它将开始跟踪其上的所有操作。完成计算后，您可以调用.backward（）并自动计算所有梯度。此张量的梯度将累积到.grad属性中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要阻止张量跟踪历史记录，可以调用.detach（）将其从计算历史中分离出来，防止将来的计算被追踪。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要防止跟踪历史记录（和使用内存），您还可以使用torch.no_grad（）包装代码块：在评估模型时，这可能特别有用，因为模型可能具有requires_grad = True的可训练参数，但我们不需要梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor和Function互相连接并构建一个非循环图，它编码完整的计算历史。每个张量都有一个.grad_fn属性，该属性引用已创建Tensor的Function（除了用户创建的Tensors  - 他们的grad_fn为None）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要计算导数，可以在Tensor上调用.backward（）。如果Tensor是标量（即它包含一个元素数据），则不需要为backward（）指定任何参数，但是如果它有更多元素，则需要指定梯度参数，该参数为同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 创建一个张量并设置requires_grad = True以跟踪它的计算\n",
    "import torch\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward object at 0x000002875198A6D8>\n"
     ]
    }
   ],
   "source": [
    "# y是作为操作的结果创建的，因此它具有grad_fn\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 均值\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000002875198E400>\n"
     ]
    }
   ],
   "source": [
    "# 自定义张量的requires_grad属性默认为False,可以通过.requires_grad_(True)方法外部修改它\n",
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度：反向传播\n",
    ".backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# out是只有1个值的标量，out.backward（）等同于out.backward(torch.tensor(1.))\n",
    "out.backward()\n",
    "# 梯度 d(out)/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 705.5146, -263.0699,  806.0997], grad_fn=<MulBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 51.2000, 512.0000,   0.0512])\n"
     ]
    }
   ],
   "source": [
    "# 在这种情况下，y不再是标量。 torch.autograd无法直接计算完整雅可比矩阵，但如果只想要矢量雅可比行列式，只需将向量作为参数向后传递\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 一个requires_grad=True的Tensor，可以通过包装torch.no_grad()阻止梯度自动计算\n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络\n",
    "可以使用torch.nn包构建神经网络。\n",
    "\n",
    "nn依赖于autograd来定义模型并区分它们。 nn.Module包含layers，以及返回输出的forward(input)方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它是一个简单的前馈网络。 它接受输入，一层接一层，然后最终给出输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络的典型训练程序如下：  \n",
    "\n",
    "定义具有一些可学习参数（或权重）的神经网络  \n",
    "迭代输入数据集  \n",
    "通过网络处理输入  \n",
    "计算损失（输出距离正确多远）  \n",
    "将梯度传播回给网络参数  \n",
    "通常使用简单的更新规则更新网络权重：weight = weight  -  learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 正方形 convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a 正方形 you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))  #reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您只需定义forward函数，当使用autograd时backward函数(计算梯度)会被自动定义。 可以在forward函数中使用任何Tensor操作。\n",
    "\n",
    "模型的可学习参数通过 net.parameters（）返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-0.1820,  0.0574, -0.1667,  0.1282,  0.0877],\n",
      "          [ 0.0826,  0.0360,  0.1517,  0.1247,  0.1280],\n",
      "          [-0.0058,  0.0741,  0.1493, -0.1632,  0.1904],\n",
      "          [ 0.1834,  0.0407,  0.0333, -0.0927, -0.1128],\n",
      "          [ 0.1746,  0.1972, -0.0220, -0.1818,  0.1954]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0579, -0.0811, -0.0812,  0.0635, -0.1285],\n",
      "          [ 0.1735, -0.0009,  0.1848, -0.0513,  0.0428],\n",
      "          [ 0.0716, -0.0263,  0.0551,  0.1119, -0.0964],\n",
      "          [ 0.1870,  0.1585, -0.1441, -0.0495, -0.0027],\n",
      "          [-0.1278,  0.1499,  0.0029, -0.0405, -0.0442]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1686,  0.1657, -0.0743,  0.1452, -0.0463],\n",
      "          [-0.0190,  0.1622, -0.1674,  0.0229,  0.1856],\n",
      "          [ 0.0542,  0.0347,  0.0791, -0.1253,  0.1645],\n",
      "          [-0.1429, -0.0046, -0.0990,  0.1510,  0.1998],\n",
      "          [ 0.1224, -0.1925, -0.1486,  0.1172,  0.0354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1598, -0.1619,  0.0020,  0.0301, -0.1901],\n",
      "          [ 0.0719, -0.0086,  0.1095, -0.1176,  0.0707],\n",
      "          [-0.0033, -0.1253, -0.0833, -0.1683,  0.0102],\n",
      "          [ 0.1229, -0.1661,  0.0861,  0.1865,  0.0946],\n",
      "          [-0.0296,  0.1715, -0.1148, -0.0668, -0.1198]]],\n",
      "\n",
      "\n",
      "        [[[-0.0408, -0.0291, -0.0380,  0.1083,  0.0485],\n",
      "          [ 0.1684,  0.0575, -0.0923,  0.0285, -0.0719],\n",
      "          [ 0.1125,  0.0546,  0.0782,  0.1461, -0.0242],\n",
      "          [ 0.0662,  0.0870,  0.1237,  0.1734, -0.1499],\n",
      "          [-0.1949, -0.0800, -0.0016,  0.1306,  0.0706]]],\n",
      "\n",
      "\n",
      "        [[[-0.0544, -0.1982,  0.0492,  0.0224, -0.1655],\n",
      "          [-0.1513,  0.1434,  0.1448,  0.0684,  0.1821],\n",
      "          [ 0.0507, -0.1810, -0.1453, -0.1052,  0.0722],\n",
      "          [-0.0484,  0.0189,  0.1974,  0.0690, -0.0461],\n",
      "          [-0.1555,  0.1165, -0.0540,  0.1865, -0.0334]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0312, -0.1620,  0.0051,  0.0857,  0.0322,  0.1780], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.0400,  0.0794,  0.0029, -0.0781, -0.0335],\n",
      "          [-0.0016, -0.0315,  0.0128,  0.0274, -0.0189],\n",
      "          [ 0.0764, -0.0654, -0.0572,  0.0546, -0.0505],\n",
      "          [ 0.0737, -0.0719,  0.0562, -0.0334, -0.0230],\n",
      "          [ 0.0593, -0.0324, -0.0716, -0.0245, -0.0246]],\n",
      "\n",
      "         [[-0.0756, -0.0648, -0.0321, -0.0375,  0.0148],\n",
      "          [-0.0230,  0.0638, -0.0431,  0.0259, -0.0702],\n",
      "          [-0.0192,  0.0497, -0.0277,  0.0336,  0.0641],\n",
      "          [ 0.0351,  0.0542, -0.0472,  0.0772, -0.0785],\n",
      "          [-0.0626, -0.0066,  0.0162, -0.0540,  0.0767]],\n",
      "\n",
      "         [[ 0.0120, -0.0454,  0.0802,  0.0768, -0.0763],\n",
      "          [ 0.0473, -0.0448, -0.0516,  0.0162,  0.0497],\n",
      "          [ 0.0753,  0.0717, -0.0526, -0.0134,  0.0249],\n",
      "          [-0.0316,  0.0150,  0.0156, -0.0561,  0.0495],\n",
      "          [ 0.0421,  0.0755, -0.0253, -0.0769, -0.0620]],\n",
      "\n",
      "         [[ 0.0554,  0.0716,  0.0518, -0.0666,  0.0152],\n",
      "          [ 0.0449,  0.0625,  0.0797, -0.0696,  0.0803],\n",
      "          [-0.0283,  0.0208, -0.0236,  0.0514,  0.0153],\n",
      "          [ 0.0129,  0.0125, -0.0071,  0.0484,  0.0047],\n",
      "          [ 0.0366,  0.0577, -0.0776,  0.0337, -0.0478]],\n",
      "\n",
      "         [[-0.0656,  0.0444, -0.0111, -0.0392, -0.0260],\n",
      "          [-0.0121,  0.0785,  0.0527, -0.0393, -0.0336],\n",
      "          [ 0.0330,  0.0768, -0.0215, -0.0168,  0.0650],\n",
      "          [-0.0519, -0.0606,  0.0537,  0.0484,  0.0752],\n",
      "          [ 0.0108,  0.0160,  0.0430,  0.0137, -0.0515]],\n",
      "\n",
      "         [[ 0.0704, -0.0399,  0.0228, -0.0469, -0.0789],\n",
      "          [-0.0321, -0.0766,  0.0631,  0.0317, -0.0258],\n",
      "          [ 0.0449,  0.0368, -0.0460, -0.0360, -0.0111],\n",
      "          [ 0.0049, -0.0647, -0.0382, -0.0459,  0.0437],\n",
      "          [ 0.0168,  0.0783,  0.0578,  0.0764, -0.0807]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0026,  0.0638, -0.0523,  0.0059,  0.0505],\n",
      "          [-0.0415,  0.0045, -0.0328,  0.0003, -0.0446],\n",
      "          [-0.0522, -0.0233, -0.0642,  0.0462, -0.0220],\n",
      "          [-0.0655, -0.0381, -0.0262,  0.0586, -0.0048],\n",
      "          [-0.0028,  0.0336,  0.0169, -0.0647, -0.0314]],\n",
      "\n",
      "         [[-0.0120, -0.0464, -0.0483, -0.0243, -0.0803],\n",
      "          [-0.0295,  0.0586,  0.0169,  0.0524,  0.0193],\n",
      "          [-0.0079,  0.0387, -0.0141, -0.0629, -0.0083],\n",
      "          [ 0.0081, -0.0282,  0.0504, -0.0356, -0.0775],\n",
      "          [ 0.0159, -0.0675, -0.0771,  0.0737,  0.0713]],\n",
      "\n",
      "         [[-0.0104,  0.0128,  0.0434, -0.0187, -0.0363],\n",
      "          [ 0.0803, -0.0382,  0.0255, -0.0802, -0.0417],\n",
      "          [-0.0484, -0.0812, -0.0262, -0.0508, -0.0018],\n",
      "          [ 0.0083, -0.0569,  0.0403, -0.0431,  0.0344],\n",
      "          [-0.0402, -0.0201, -0.0080, -0.0479,  0.0255]],\n",
      "\n",
      "         [[ 0.0194,  0.0335,  0.0091,  0.0266,  0.0349],\n",
      "          [ 0.0780, -0.0626, -0.0809,  0.0553,  0.0745],\n",
      "          [-0.0815,  0.0778,  0.0557, -0.0597,  0.0143],\n",
      "          [-0.0069,  0.0221,  0.0159, -0.0558,  0.0654],\n",
      "          [-0.0571, -0.0685, -0.0709,  0.0224, -0.0309]],\n",
      "\n",
      "         [[-0.0650,  0.0598,  0.0620,  0.0412,  0.0530],\n",
      "          [ 0.0089, -0.0347, -0.0057,  0.0060, -0.0241],\n",
      "          [ 0.0652,  0.0726,  0.0457,  0.0530, -0.0327],\n",
      "          [ 0.0532,  0.0349, -0.0705, -0.0791, -0.0397],\n",
      "          [ 0.0729,  0.0050, -0.0456,  0.0091, -0.0336]],\n",
      "\n",
      "         [[ 0.0177,  0.0638, -0.0437,  0.0371,  0.0675],\n",
      "          [-0.0318,  0.0506, -0.0375, -0.0131, -0.0213],\n",
      "          [ 0.0814,  0.0392, -0.0559,  0.0369, -0.0353],\n",
      "          [ 0.0058,  0.0795, -0.0108,  0.0194,  0.0386],\n",
      "          [ 0.0649, -0.0600,  0.0153, -0.0624,  0.0580]]],\n",
      "\n",
      "\n",
      "        [[[-0.0592, -0.0386, -0.0635,  0.0601,  0.0065],\n",
      "          [-0.0777,  0.0122, -0.0731,  0.0496,  0.0123],\n",
      "          [ 0.0207,  0.0603, -0.0684,  0.0703, -0.0350],\n",
      "          [ 0.0531, -0.0458,  0.0714, -0.0454,  0.0804],\n",
      "          [ 0.0465, -0.0062, -0.0105, -0.0409, -0.0604]],\n",
      "\n",
      "         [[-0.0536,  0.0786, -0.0439, -0.0379,  0.0282],\n",
      "          [ 0.0286, -0.0379, -0.0791, -0.0226,  0.0463],\n",
      "          [-0.0784,  0.0117,  0.0223, -0.0065, -0.0321],\n",
      "          [ 0.0284,  0.0630,  0.0806, -0.0478,  0.0391],\n",
      "          [-0.0660, -0.0183, -0.0076, -0.0129,  0.0527]],\n",
      "\n",
      "         [[-0.0642, -0.0314, -0.0322,  0.0125, -0.0811],\n",
      "          [-0.0173, -0.0469, -0.0331,  0.0091, -0.0125],\n",
      "          [-0.0233, -0.0704,  0.0582, -0.0183, -0.0335],\n",
      "          [ 0.0051, -0.0165,  0.0176, -0.0731, -0.0706],\n",
      "          [ 0.0775,  0.0700,  0.0716,  0.0090,  0.0692]],\n",
      "\n",
      "         [[ 0.0720, -0.0284, -0.0226, -0.0497,  0.0230],\n",
      "          [-0.0206,  0.0572, -0.0587, -0.0653,  0.0144],\n",
      "          [ 0.0042,  0.0611, -0.0054, -0.0383, -0.0311],\n",
      "          [-0.0229, -0.0154, -0.0461, -0.0471,  0.0246],\n",
      "          [-0.0528, -0.0037, -0.0163, -0.0631,  0.0206]],\n",
      "\n",
      "         [[-0.0466,  0.0753, -0.0036, -0.0066, -0.0717],\n",
      "          [-0.0393, -0.0391, -0.0354, -0.0801,  0.0678],\n",
      "          [ 0.0145, -0.0056,  0.0698, -0.0086,  0.0021],\n",
      "          [ 0.0647, -0.0146, -0.0756,  0.0467,  0.0696],\n",
      "          [ 0.0180, -0.0477,  0.0580,  0.0090,  0.0059]],\n",
      "\n",
      "         [[ 0.0031, -0.0709, -0.0053,  0.0335,  0.0267],\n",
      "          [-0.0780,  0.0638,  0.0398,  0.0157,  0.0781],\n",
      "          [ 0.0076, -0.0504,  0.0066, -0.0452,  0.0263],\n",
      "          [ 0.0046, -0.0741,  0.0143, -0.0602,  0.0597],\n",
      "          [-0.0119,  0.0384,  0.0786,  0.0672,  0.0511]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0765, -0.0107, -0.0481, -0.0198,  0.0774],\n",
      "          [ 0.0170, -0.0791,  0.0537,  0.0737,  0.0221],\n",
      "          [ 0.0133,  0.0218, -0.0362, -0.0405, -0.0220],\n",
      "          [-0.0802, -0.0027, -0.0809, -0.0217, -0.0803],\n",
      "          [ 0.0238,  0.0028, -0.0235, -0.0472, -0.0072]],\n",
      "\n",
      "         [[ 0.0707,  0.0082,  0.0490, -0.0488,  0.0459],\n",
      "          [-0.0217,  0.0275, -0.0731,  0.0753, -0.0806],\n",
      "          [ 0.0631, -0.0158,  0.0453, -0.0750, -0.0619],\n",
      "          [ 0.0142, -0.0751, -0.0633,  0.0578, -0.0183],\n",
      "          [-0.0405,  0.0635,  0.0717, -0.0456, -0.0669]],\n",
      "\n",
      "         [[ 0.0529, -0.0350, -0.0546,  0.0162, -0.0006],\n",
      "          [-0.0560,  0.0283,  0.0132,  0.0238, -0.0685],\n",
      "          [ 0.0270, -0.0785, -0.0041,  0.0611,  0.0364],\n",
      "          [-0.0047,  0.0351,  0.0035, -0.0609,  0.0212],\n",
      "          [-0.0185,  0.0725, -0.0035, -0.0678,  0.0093]],\n",
      "\n",
      "         [[ 0.0028, -0.0690,  0.0547,  0.0539, -0.0275],\n",
      "          [ 0.0306,  0.0275, -0.0010,  0.0205, -0.0717],\n",
      "          [ 0.0363, -0.0764,  0.0481, -0.0634, -0.0777],\n",
      "          [ 0.0661, -0.0739, -0.0342, -0.0159,  0.0110],\n",
      "          [-0.0156,  0.0293, -0.0167,  0.0389,  0.0486]],\n",
      "\n",
      "         [[-0.0323, -0.0269,  0.0590, -0.0266, -0.0298],\n",
      "          [ 0.0519,  0.0393,  0.0387, -0.0062, -0.0334],\n",
      "          [-0.0250,  0.0136,  0.0020, -0.0217,  0.0209],\n",
      "          [-0.0668,  0.0399, -0.0327,  0.0624, -0.0148],\n",
      "          [-0.0370,  0.0021, -0.0488, -0.0132,  0.0646]],\n",
      "\n",
      "         [[ 0.0386, -0.0064,  0.0668, -0.0180, -0.0714],\n",
      "          [-0.0111, -0.0779, -0.0536, -0.0524,  0.0357],\n",
      "          [ 0.0061,  0.0120,  0.0481, -0.0087, -0.0811],\n",
      "          [ 0.0344,  0.0110, -0.0233,  0.0511,  0.0637],\n",
      "          [ 0.0280,  0.0100,  0.0256,  0.0317,  0.0230]]],\n",
      "\n",
      "\n",
      "        [[[-0.0259, -0.0565,  0.0157, -0.0005, -0.0018],\n",
      "          [-0.0261,  0.0723, -0.0156,  0.0765,  0.0178],\n",
      "          [-0.0007,  0.0421, -0.0676, -0.0790, -0.0193],\n",
      "          [-0.0177,  0.0568,  0.0652, -0.0088, -0.0544],\n",
      "          [ 0.0293,  0.0721,  0.0263,  0.0703, -0.0714]],\n",
      "\n",
      "         [[ 0.0256, -0.0112,  0.0108, -0.0147,  0.0731],\n",
      "          [ 0.0615,  0.0693,  0.0673, -0.0580,  0.0018],\n",
      "          [-0.0717, -0.0740, -0.0370,  0.0680, -0.0403],\n",
      "          [-0.0368, -0.0745, -0.0754, -0.0301, -0.0602],\n",
      "          [-0.0308,  0.0436,  0.0317,  0.0568,  0.0300]],\n",
      "\n",
      "         [[-0.0565, -0.0736,  0.0732,  0.0451, -0.0699],\n",
      "          [ 0.0409, -0.0505,  0.0478, -0.0504,  0.0039],\n",
      "          [ 0.0429,  0.0010,  0.0683,  0.0396,  0.0576],\n",
      "          [-0.0316, -0.0702,  0.0553,  0.0645,  0.0586],\n",
      "          [-0.0196, -0.0098,  0.0040, -0.0061, -0.0085]],\n",
      "\n",
      "         [[-0.0133,  0.0502,  0.0336,  0.0009,  0.0406],\n",
      "          [ 0.0218, -0.0502,  0.0109, -0.0639,  0.0504],\n",
      "          [ 0.0600,  0.0241,  0.0733,  0.0328, -0.0405],\n",
      "          [-0.0745, -0.0321,  0.0127, -0.0776, -0.0524],\n",
      "          [-0.0185,  0.0119, -0.0218,  0.0297, -0.0546]],\n",
      "\n",
      "         [[ 0.0116,  0.0725, -0.0814, -0.0479, -0.0260],\n",
      "          [-0.0167,  0.0762,  0.0543,  0.0784,  0.0039],\n",
      "          [ 0.0675, -0.0328,  0.0235, -0.0474,  0.0079],\n",
      "          [-0.0231, -0.0348, -0.0745,  0.0753, -0.0343],\n",
      "          [ 0.0307, -0.0102, -0.0401,  0.0156,  0.0012]],\n",
      "\n",
      "         [[ 0.0810, -0.0162, -0.0388, -0.0282, -0.0341],\n",
      "          [ 0.0172, -0.0791, -0.0608,  0.0431, -0.0332],\n",
      "          [-0.0537, -0.0727, -0.0742,  0.0122,  0.0608],\n",
      "          [-0.0622, -0.0073, -0.0090, -0.0142,  0.0317],\n",
      "          [ 0.0678,  0.0183, -0.0300,  0.0333, -0.0005]]],\n",
      "\n",
      "\n",
      "        [[[-0.0761,  0.0640, -0.0207,  0.0675,  0.0050],\n",
      "          [-0.0196, -0.0748, -0.0702,  0.0343, -0.0540],\n",
      "          [ 0.0453,  0.0502,  0.0474,  0.0779,  0.0469],\n",
      "          [ 0.0119,  0.0090, -0.0290,  0.0375,  0.0221],\n",
      "          [ 0.0200,  0.0074,  0.0592, -0.0415,  0.0423]],\n",
      "\n",
      "         [[ 0.0146, -0.0773,  0.0039, -0.0504, -0.0724],\n",
      "          [ 0.0690, -0.0512,  0.0176, -0.0431, -0.0547],\n",
      "          [ 0.0769,  0.0665,  0.0352,  0.0600,  0.0296],\n",
      "          [-0.0690,  0.0523,  0.0054,  0.0241,  0.0381],\n",
      "          [-0.0683, -0.0528,  0.0533,  0.0388,  0.0053]],\n",
      "\n",
      "         [[ 0.0668, -0.0628,  0.0553, -0.0590, -0.0137],\n",
      "          [-0.0650, -0.0783,  0.0759,  0.0270, -0.0015],\n",
      "          [ 0.0475,  0.0737,  0.0349,  0.0010, -0.0511],\n",
      "          [ 0.0548,  0.0644,  0.0114,  0.0004, -0.0123],\n",
      "          [-0.0709,  0.0220, -0.0190,  0.0476, -0.0205]],\n",
      "\n",
      "         [[ 0.0578,  0.0583, -0.0040,  0.0069,  0.0301],\n",
      "          [ 0.0017, -0.0039,  0.0716, -0.0315, -0.0257],\n",
      "          [-0.0438,  0.0565,  0.0097, -0.0688, -0.0608],\n",
      "          [ 0.0490, -0.0221,  0.0425,  0.0236, -0.0130],\n",
      "          [-0.0209, -0.0702, -0.0521,  0.0467, -0.0526]],\n",
      "\n",
      "         [[ 0.0584,  0.0590, -0.0474,  0.0789,  0.0324],\n",
      "          [ 0.0235,  0.0587, -0.0379,  0.0585,  0.0317],\n",
      "          [ 0.0729, -0.0081, -0.0773, -0.0368,  0.0719],\n",
      "          [ 0.0640,  0.0209,  0.0745,  0.0347, -0.0124],\n",
      "          [ 0.0783,  0.0770,  0.0243,  0.0666,  0.0199]],\n",
      "\n",
      "         [[ 0.0698, -0.0784,  0.0154, -0.0777,  0.0511],\n",
      "          [ 0.0572,  0.0099, -0.0176, -0.0120,  0.0415],\n",
      "          [ 0.0669, -0.0487, -0.0334, -0.0569,  0.0542],\n",
      "          [-0.0504, -0.0305, -0.0113,  0.0190, -0.0652],\n",
      "          [-0.0689,  0.0259,  0.0529,  0.0768, -0.0086]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0229, -0.0714, -0.0408,  0.0056, -0.0396, -0.0677,  0.0632, -0.0042,\n",
      "        -0.0629,  0.0233,  0.0437, -0.0383,  0.0149,  0.0624,  0.0608,  0.0127],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0047,  0.0118,  0.0081,  ..., -0.0394, -0.0037, -0.0472],\n",
      "        [ 0.0302, -0.0323,  0.0317,  ...,  0.0246,  0.0451,  0.0244],\n",
      "        [ 0.0200,  0.0089, -0.0021,  ..., -0.0341, -0.0173, -0.0034],\n",
      "        ...,\n",
      "        [-0.0271, -0.0484, -0.0487,  ..., -0.0211, -0.0059,  0.0480],\n",
      "        [-0.0105,  0.0081,  0.0030,  ...,  0.0408,  0.0275, -0.0340],\n",
      "        [-0.0138,  0.0413,  0.0272,  ...,  0.0309, -0.0394,  0.0087]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0365,  0.0016, -0.0270, -0.0292, -0.0385, -0.0234,  0.0218,  0.0397,\n",
      "         0.0182,  0.0441, -0.0456,  0.0292, -0.0499,  0.0198,  0.0134, -0.0200,\n",
      "         0.0379, -0.0012, -0.0202,  0.0371,  0.0482,  0.0096,  0.0468,  0.0072,\n",
      "        -0.0170, -0.0062,  0.0013,  0.0037,  0.0482,  0.0386, -0.0178, -0.0323,\n",
      "        -0.0430,  0.0267,  0.0268, -0.0441,  0.0312, -0.0223, -0.0373, -0.0105,\n",
      "        -0.0136,  0.0175, -0.0168, -0.0479,  0.0303, -0.0474,  0.0160,  0.0285,\n",
      "         0.0238, -0.0407,  0.0244,  0.0034, -0.0019,  0.0062, -0.0075, -0.0041,\n",
      "        -0.0211, -0.0191, -0.0137,  0.0065,  0.0089,  0.0472, -0.0440,  0.0196,\n",
      "        -0.0089, -0.0282, -0.0317, -0.0453,  0.0283, -0.0203, -0.0005, -0.0384,\n",
      "         0.0476, -0.0455,  0.0201, -0.0100, -0.0091, -0.0096, -0.0082, -0.0456,\n",
      "         0.0402, -0.0464, -0.0128,  0.0233, -0.0018, -0.0189,  0.0453,  0.0479,\n",
      "        -0.0464,  0.0171, -0.0219, -0.0004, -0.0460, -0.0022,  0.0205,  0.0299,\n",
      "        -0.0402,  0.0213,  0.0081, -0.0191,  0.0120, -0.0451,  0.0073, -0.0317,\n",
      "        -0.0310, -0.0383, -0.0046,  0.0453, -0.0151,  0.0229, -0.0474,  0.0495,\n",
      "        -0.0495, -0.0218,  0.0253,  0.0456, -0.0015, -0.0380,  0.0481, -0.0219],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0414,  0.0636,  0.0867,  ..., -0.0088, -0.0176,  0.0383],\n",
      "        [-0.0675, -0.0898, -0.0802,  ..., -0.0825,  0.0166, -0.0782],\n",
      "        [-0.0815,  0.0332, -0.0140,  ...,  0.0911, -0.0046,  0.0706],\n",
      "        ...,\n",
      "        [ 0.0191,  0.0616,  0.0417,  ..., -0.0279, -0.0223, -0.0681],\n",
      "        [-0.0114, -0.0402, -0.0870,  ..., -0.0375,  0.0145,  0.0689],\n",
      "        [ 0.0010, -0.0114,  0.0557,  ...,  0.0452, -0.0767, -0.0448]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0877, -0.0435, -0.0596, -0.0618,  0.0787, -0.0612, -0.0766, -0.0071,\n",
      "         0.0693,  0.0487, -0.0801, -0.0281,  0.0040, -0.0090,  0.0786, -0.0624,\n",
      "         0.0144, -0.0562,  0.0250,  0.0266, -0.0470,  0.0324,  0.0483, -0.0911,\n",
      "        -0.0403,  0.0070,  0.0310,  0.0828,  0.0542, -0.0808, -0.0112,  0.0649,\n",
      "        -0.0789,  0.0360, -0.0265,  0.0439, -0.0728,  0.0619,  0.0220, -0.0390,\n",
      "        -0.0534, -0.0633, -0.0026, -0.0089,  0.0372, -0.0718, -0.0134, -0.0314,\n",
      "         0.0138,  0.0533,  0.0341, -0.0172,  0.0485,  0.0585,  0.0542, -0.0735,\n",
      "         0.0871,  0.0521, -0.0111,  0.0670, -0.0057,  0.0336, -0.0082, -0.0006,\n",
      "         0.0159,  0.0369, -0.0340, -0.0825, -0.0879, -0.0521,  0.0522,  0.0285,\n",
      "        -0.0363, -0.0609,  0.0779, -0.0644,  0.0013,  0.0889,  0.0641, -0.0875,\n",
      "         0.0513,  0.0170, -0.0463, -0.0278], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0204, -0.0411,  0.0497,  0.0826,  0.0478,  0.0386,  0.0144, -0.0712,\n",
      "         -0.0834, -0.0502,  0.0449, -0.0293,  0.0900,  0.1073,  0.0398,  0.0516,\n",
      "         -0.0396,  0.0658,  0.0368,  0.0660, -0.0358,  0.1000, -0.0340, -0.0102,\n",
      "         -0.0616,  0.0997, -0.0543,  0.0321, -0.0401,  0.0482, -0.0622,  0.0614,\n",
      "         -0.0610,  0.0937,  0.0277,  0.0123, -0.0734,  0.1048,  0.0729,  0.0767,\n",
      "         -0.0678,  0.0790, -0.0646, -0.0666, -0.0733, -0.0520, -0.0932,  0.0862,\n",
      "         -0.0161, -0.0554, -0.0835,  0.0554,  0.0664,  0.0151,  0.0222, -0.0825,\n",
      "         -0.0203, -0.0043,  0.0926,  0.0904,  0.0751,  0.0096, -0.0884, -0.0928,\n",
      "         -0.0779,  0.0657,  0.0489,  0.0086,  0.0631,  0.0212, -0.1010, -0.0968,\n",
      "          0.0941,  0.0491, -0.0528,  0.0129,  0.0130,  0.0527, -0.0855, -0.0806,\n",
      "          0.0593,  0.0870,  0.0828,  0.0980],\n",
      "        [-0.0695,  0.0038,  0.0287, -0.0843,  0.0492, -0.1084,  0.0896, -0.1040,\n",
      "          0.1044, -0.0546,  0.0267, -0.1071,  0.0607, -0.0207, -0.0942,  0.0557,\n",
      "         -0.1086, -0.0605,  0.0016,  0.0150,  0.0735,  0.0351, -0.0316,  0.0266,\n",
      "         -0.0339,  0.0104, -0.0248,  0.0523, -0.0488, -0.0218, -0.0539, -0.1069,\n",
      "          0.0843,  0.0905, -0.1000, -0.0811, -0.0324, -0.0573,  0.0723,  0.0558,\n",
      "         -0.0304, -0.1000,  0.0069, -0.0448,  0.1085, -0.0205,  0.0577, -0.0802,\n",
      "          0.0938, -0.0544, -0.0970,  0.0585,  0.0761, -0.0729, -0.0148,  0.0514,\n",
      "         -0.0889, -0.0744, -0.0649,  0.0955, -0.0578,  0.0308, -0.0619, -0.0625,\n",
      "         -0.0778,  0.1029, -0.1083,  0.0126,  0.0083, -0.0305, -0.0068, -0.0120,\n",
      "          0.0214,  0.0349,  0.1006, -0.0735,  0.0121,  0.0171, -0.0521, -0.0162,\n",
      "          0.0966, -0.0816,  0.0897,  0.0300],\n",
      "        [-0.0427,  0.0524,  0.0401,  0.0877,  0.0156, -0.0820,  0.0549, -0.0537,\n",
      "          0.1054,  0.0717, -0.0393, -0.0970,  0.0157,  0.0720,  0.0919, -0.0248,\n",
      "         -0.0268,  0.0967,  0.0030,  0.0357,  0.0557, -0.0196, -0.0858,  0.0740,\n",
      "         -0.0913,  0.0385,  0.0108, -0.0330,  0.0923, -0.0780, -0.0261, -0.0372,\n",
      "         -0.0537, -0.0985, -0.0782,  0.0042, -0.0331, -0.0090,  0.0781, -0.1075,\n",
      "         -0.0330, -0.1013, -0.0013, -0.0352,  0.0517, -0.1051, -0.0586,  0.0951,\n",
      "         -0.0983,  0.0805, -0.1041, -0.0031, -0.1000,  0.0915, -0.0651,  0.0525,\n",
      "          0.0979, -0.0348,  0.0536, -0.0641, -0.0825,  0.0125, -0.0096, -0.0418,\n",
      "         -0.0785,  0.0899, -0.0273,  0.0371, -0.0291, -0.0587, -0.0615, -0.0135,\n",
      "         -0.0904, -0.0657,  0.0864,  0.0100,  0.0422, -0.0463,  0.0487, -0.0431,\n",
      "         -0.0486, -0.0290, -0.0327, -0.0538],\n",
      "        [ 0.0227, -0.0394, -0.0137,  0.0977, -0.0626,  0.0205, -0.0885, -0.0714,\n",
      "         -0.0205,  0.1000,  0.0565, -0.0264, -0.0504, -0.0387, -0.0307, -0.0678,\n",
      "         -0.0753,  0.0838, -0.0085,  0.0204,  0.0181,  0.0805,  0.0109,  0.0883,\n",
      "         -0.0594, -0.0819,  0.0700,  0.0345, -0.0493,  0.0082, -0.0858, -0.0440,\n",
      "         -0.0166, -0.0752, -0.0452, -0.0597,  0.0039,  0.0249,  0.0231, -0.0538,\n",
      "         -0.0833,  0.0595,  0.0636, -0.0311,  0.0150,  0.0599,  0.0877, -0.0518,\n",
      "         -0.1049,  0.0555,  0.0927, -0.0155,  0.0302,  0.0609,  0.0124,  0.0032,\n",
      "         -0.0357,  0.0356, -0.0349,  0.0745, -0.0348, -0.0727,  0.0448, -0.0120,\n",
      "          0.0969,  0.0862, -0.0551,  0.0086, -0.0612,  0.1089, -0.0342, -0.0005,\n",
      "         -0.0098,  0.0425, -0.1003, -0.0755, -0.0266,  0.0435,  0.0660,  0.0186,\n",
      "          0.0548, -0.0266,  0.0007, -0.0720],\n",
      "        [-0.0793,  0.0285, -0.0754,  0.0931, -0.0026,  0.0862, -0.1018, -0.0960,\n",
      "         -0.0350, -0.0723, -0.0345, -0.0652, -0.0490,  0.0638, -0.0839,  0.0684,\n",
      "         -0.0083,  0.0931,  0.0038, -0.0174, -0.0349,  0.0630,  0.0437, -0.0936,\n",
      "         -0.0812,  0.0273, -0.0569,  0.0539, -0.0506, -0.0727,  0.0754,  0.0948,\n",
      "          0.1072, -0.0650,  0.0842,  0.0255, -0.0531,  0.0477, -0.0452, -0.0501,\n",
      "         -0.1086, -0.0262,  0.0087,  0.0353, -0.0589, -0.0182, -0.0692,  0.0809,\n",
      "         -0.0834, -0.0428, -0.0173, -0.0206, -0.0551, -0.0436, -0.0197,  0.0407,\n",
      "         -0.0907, -0.0594,  0.0052, -0.0517,  0.0681, -0.0792, -0.0603, -0.0862,\n",
      "          0.0740,  0.0849,  0.0761,  0.0456,  0.0264,  0.0082, -0.0131, -0.0136,\n",
      "          0.0717, -0.0682,  0.0624,  0.0634,  0.0761, -0.0581, -0.0747, -0.0651,\n",
      "          0.0341,  0.0220, -0.0844, -0.0714],\n",
      "        [-0.1068, -0.0672,  0.1028, -0.0441, -0.1072, -0.0554,  0.0147,  0.0481,\n",
      "          0.1079,  0.0699, -0.0349, -0.0244,  0.0557,  0.0736, -0.0572,  0.0753,\n",
      "          0.0352, -0.0831,  0.0319, -0.1013, -0.0220,  0.0907, -0.0489, -0.0757,\n",
      "         -0.0525,  0.0385, -0.0405,  0.0335,  0.0731, -0.0770, -0.0935,  0.0940,\n",
      "         -0.0414,  0.0249, -0.0088, -0.1086, -0.0456, -0.0844, -0.0989,  0.0717,\n",
      "         -0.0718, -0.0158,  0.0326, -0.0487,  0.0581, -0.1070, -0.0294,  0.0018,\n",
      "         -0.1068, -0.0920,  0.0539, -0.1046,  0.0702, -0.0659, -0.0517, -0.0398,\n",
      "         -0.0329, -0.0448, -0.0078,  0.0229,  0.0784, -0.0928, -0.0444,  0.0869,\n",
      "         -0.0345, -0.0688,  0.0215,  0.0230, -0.1039, -0.0441,  0.0775, -0.0104,\n",
      "         -0.0055,  0.1057,  0.0203,  0.0703, -0.0059,  0.0907, -0.0631, -0.1037,\n",
      "         -0.0758,  0.0408, -0.0621,  0.0693],\n",
      "        [ 0.0262, -0.0922, -0.0594,  0.0671,  0.0059, -0.0735,  0.0566,  0.1088,\n",
      "         -0.0387,  0.0897,  0.0646,  0.0719, -0.1058, -0.0814, -0.0994,  0.0981,\n",
      "         -0.0326, -0.1020,  0.0286, -0.0557,  0.0259, -0.1065,  0.0329,  0.0296,\n",
      "          0.0592,  0.0630,  0.0208,  0.0322, -0.0181, -0.0475,  0.0278,  0.0619,\n",
      "          0.0098,  0.0724,  0.1015,  0.0482, -0.0654, -0.1063,  0.0978, -0.0870,\n",
      "          0.0832,  0.0039, -0.0454, -0.0634, -0.0535, -0.0767,  0.0966, -0.0439,\n",
      "          0.0310, -0.0707,  0.0426, -0.0656, -0.0472, -0.0327, -0.0891,  0.0756,\n",
      "          0.0139,  0.0810, -0.0968,  0.0263, -0.0097,  0.0780,  0.0107,  0.0720,\n",
      "          0.0684,  0.0790,  0.0667, -0.0626,  0.0833, -0.0928,  0.0733, -0.0892,\n",
      "         -0.0913,  0.0550,  0.0569,  0.0227, -0.0282, -0.0833,  0.0225, -0.0061,\n",
      "         -0.1008,  0.0365, -0.1043, -0.0385],\n",
      "        [-0.0358, -0.0854,  0.0740, -0.1060, -0.0104, -0.0050, -0.0235, -0.0728,\n",
      "          0.0860, -0.0416,  0.0318, -0.0951, -0.0587,  0.0234, -0.0444,  0.0383,\n",
      "          0.0597, -0.0899,  0.0256, -0.0116, -0.0491, -0.0537,  0.0930, -0.0897,\n",
      "          0.0890,  0.1040, -0.0150, -0.0565,  0.0331, -0.0434,  0.0843,  0.0107,\n",
      "          0.0346, -0.0083, -0.0959, -0.0887, -0.0172, -0.0001,  0.0413,  0.0802,\n",
      "          0.0685, -0.0389,  0.0072, -0.0427,  0.0602, -0.0192, -0.0138,  0.0151,\n",
      "         -0.1002, -0.0747, -0.0198,  0.0843, -0.1012, -0.0291, -0.0059,  0.0256,\n",
      "          0.0838,  0.0933, -0.0557, -0.1036, -0.0307,  0.0843, -0.0127, -0.0921,\n",
      "          0.0267, -0.0452,  0.0821, -0.0590, -0.0721, -0.0769, -0.1071,  0.0383,\n",
      "          0.0627,  0.0326, -0.0207,  0.0556, -0.0593,  0.0157, -0.0071,  0.1005,\n",
      "          0.0229, -0.0573,  0.0836, -0.0917],\n",
      "        [-0.0255,  0.0823, -0.1052, -0.1082,  0.0660,  0.0532,  0.0793,  0.0174,\n",
      "         -0.1068, -0.0417, -0.0605,  0.0726,  0.0902, -0.0425, -0.0794,  0.0256,\n",
      "         -0.0829,  0.0365, -0.0361, -0.0437,  0.0822,  0.0754,  0.1068,  0.0687,\n",
      "         -0.0962, -0.0373, -0.0599, -0.0611, -0.0351,  0.0733, -0.1021,  0.0090,\n",
      "          0.0737,  0.0919,  0.0930,  0.1065, -0.0215,  0.0734,  0.0418, -0.0127,\n",
      "         -0.1019, -0.0094, -0.0962, -0.0874, -0.0302, -0.0987, -0.0760, -0.0501,\n",
      "         -0.0798, -0.0430, -0.0805, -0.1030, -0.0449, -0.0128,  0.0256,  0.0014,\n",
      "          0.0425, -0.0562, -0.1030,  0.0369, -0.0844,  0.0277,  0.0351, -0.1007,\n",
      "          0.0301,  0.0157, -0.0491, -0.0453,  0.0830, -0.0117,  0.0335, -0.1006,\n",
      "         -0.0672,  0.0917, -0.0527, -0.0645,  0.0373, -0.0448, -0.0130, -0.0142,\n",
      "          0.0567,  0.0519,  0.0628,  0.0902],\n",
      "        [ 0.0822, -0.0974,  0.0261, -0.0298,  0.0444, -0.0048, -0.0598, -0.0175,\n",
      "         -0.0149, -0.1065, -0.0342,  0.0246, -0.0765, -0.0065,  0.0670,  0.0380,\n",
      "          0.0564,  0.0939,  0.0377,  0.1066, -0.0233, -0.0827,  0.0384, -0.0637,\n",
      "          0.0457, -0.0189,  0.0293,  0.0896,  0.0500,  0.0450, -0.0251, -0.0243,\n",
      "         -0.0066,  0.1084,  0.0055, -0.0027,  0.0656, -0.0420, -0.0059,  0.0141,\n",
      "          0.0865,  0.0879, -0.0568,  0.0309, -0.0047, -0.0151, -0.0578,  0.0716,\n",
      "         -0.0546, -0.0750,  0.0282, -0.0165,  0.0142,  0.0155,  0.0512, -0.0182,\n",
      "         -0.0695, -0.0732,  0.1007, -0.0017, -0.1032,  0.0756,  0.0985, -0.0037,\n",
      "          0.0308, -0.0130,  0.0229,  0.1060, -0.0883, -0.0308, -0.0531, -0.0749,\n",
      "         -0.0945, -0.0685, -0.0211,  0.0777,  0.0889,  0.0173, -0.0668, -0.0424,\n",
      "         -0.1076,  0.0473,  0.0543,  0.0520]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0900, -0.0941, -0.0367,  0.0426, -0.0873,  0.0338,  0.0129,  0.1036,\n",
      "        -0.0582,  0.0758], requires_grad=True)]\n",
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试一个随机的32x32输入。 注意：此网络（LeNet）要求输入大小为32x32。 要在MNIST数据集上使用此网络，请将数据集中的图像调整为32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0942, -0.0903, -0.0046,  0.0826, -0.1429,  0.0309, -0.0149,  0.0419,\n",
      "         -0.1187,  0.1278]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有参数的梯度缓存置0，反向传播采用随机梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整个torch.nn包只支持小批量样本的输入，而不是单个样本。\n",
    "\n",
    "例如，nn.Conv2d将采用4D张量的nSamples x nChannels x Height x Width。\n",
    "\n",
    "如果只有一个样本，只需使用input.unsqueeze(0)变成假批量维度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回顾\n",
    "torch.Tensor  - 支持autograd操作（如backward（））的多维数组。  \n",
    "nn.Module  - 神经网络模块。包含形成深度神经网络构建的各种模块和损失函数。，帮助将它们转移到GPU，导出，加载等。  \n",
    "nn.Parameter  - 一种Tensor，在被指定为Module的属性时自动注册为参数。  \n",
    "autograd.Function  - 实现autograd操作的forward 和backward定义。每个Tensor操作都会创建至少一个Function节点，该节点连接到创建Tensor并对其历史进行编码的函数。\n",
    "### 已完成\n",
    "定义网络结构\n",
    "处理输入和调用反向传播\n",
    "### 未完成\n",
    "计算损失\n",
    "更新网络权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "nn包下有几种不同的损失函数。 一个简单的损失是：nn.MSELoss计算输入和目标之间的均方误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3692, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用.grad_fn 属性追踪反向传播方向的损失，如下所示  \n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d  \n",
    "      -> view -> linear -> relu -> linear -> relu -> linear  \n",
    "      -> MSELoss  \n",
    "      -> loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们调用loss.backward（）时，整个graph 被区分为w.r.t. 损失，图中所有具有requires_grad = True的张量将使用梯度累积的.grad Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x000002870B6C29E8>\n",
      "<ThAddmmBackward object at 0x000002870B6C2AC8>\n",
      "<ExpandBackward object at 0x000002870B6C29E8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop\n",
    "要反向传播误差，只要做lost.backward（）。 您需要清除已存在梯度，否则梯度将累积到已存在梯度  \n",
    "现在将调用loss.backward（），并查看conv1在backward之前和之后的偏置梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0010, -0.0006, -0.0027, -0.0136,  0.0040,  0.0038])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新权重\n",
    "实践中使用的最简单的更新规则是随机梯度下降（SGD）  \n",
    "weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)  #weight内部减"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是，当您使用神经网络时，您希望使用各种不同的更新规则，例如SGD，Nesterov-SGD，Adam，RMSProp等。为了实现这一点，我们构建了一个小包：torch.optim，它实现了所有这些方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察如何使用optimizer.zero_grad（）手动将梯度缓冲区设置为零。 这是因为梯度是按Backprop部分中的说明累积的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练一个分类器\n",
    "数据可以用python包加载成numpy array，再转化成torch.*Tensor  \n",
    "专门针对视觉，我们创建了一个名为torchvision的软件包，它包含用于常见数据集的数据加载器，如Imagenet，CIFAR10，MNIST等，以及用于图像的数据转换器，即torchvision.datasets和torch.utils.data.DataLoader。  \n",
    "CIFAR-10数据集：\n",
    "size 3x32x32\n",
    "10类：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练图像分类器,将按顺序执行以下步骤：\n",
    "\n",
    "使用torchvision加载和标准化CIFAR10训练和测试数据集  \n",
    "定义卷积神经网络  \n",
    "定义损失函数  \n",
    "在训练数据上训练网络  \n",
    "在测试数据上测试网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用torchvision加载CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# torchvision数据集的输出是范围[0,1]的PILImage图像。 我们将它们转换为归一化范围的张量[-1,1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2871dc12b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dog plane   cat truck\n"
     ]
    }
   ],
   "source": [
    "# 显示一些训练集看看\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 将前面的神经网络从1-channel改成3-channel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) #第一个nn.Conv2d的参数2和第二个nn.Conv2d的参数1，数字要相同\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Classification Cross-Entropy loss and SGD with momentum\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "我们只需循环遍历数据迭代器，并将输入提供给网络并进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.137\n",
      "[1,  4000] loss: 1.799\n",
      "[1,  6000] loss: 1.655\n",
      "[1,  8000] loss: 1.581\n",
      "[1, 10000] loss: 1.502\n",
      "[1, 12000] loss: 1.448\n",
      "[2,  2000] loss: 1.395\n",
      "[2,  4000] loss: 1.358\n",
      "[2,  6000] loss: 1.337\n",
      "[2,  8000] loss: 1.292\n",
      "[2, 10000] loss: 1.284\n",
      "[2, 12000] loss: 1.263\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在测试集上测试\n",
    "已经训练了2个epoch,通过预测标签和真实标签做对比  \n",
    "第一步，从测试集中显示一个图像以熟悉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztfWmMHdl13ner6u2vX+/d7ObOITm7NDMajSRblmXJTkayLRmJ7Mgx7EGiYIDAQuzAQCzHPxwB+WEjgR0HcBQMLFmyY1hWJNlSZMWRPFq9jDScVZrhcBmuTTa72Xv321/VzY9zbp3TG9lkU2x2+34A0cVb9aruvXWr6pzzncVYa+Hh4eHhsf0RbHUHPDw8PDxuDfwL3cPDw2OHwL/QPTw8PHYI/Avdw8PDY4fAv9A9PDw8dgj8C93Dw8Njh8C/0D08PDx2CDb1QjfGPG6MOWGMOW2M+cit6pSHh4eHx43D3GxgkTEmBHASwE8AGAPwLICft9a+euu65+Hh4eGxUUSb+O1jAE5ba88AgDHm0wDeD2DdF3qxWLQ9PT2buKSHh4fHPz6Mj49PWWsHr3fcZl7ouwFcVP8fA/CWa/2gp6cHTz755CYu6eHh4fGPDx/96EfPb+S4zdjQzRptq+w3xpgnjTHHjDHHarXaJi7n4eHh4XEtbOaFPgZgr/r/HgCXVx5krX3KWvuotfbRYrG4ict5eHh4eFwLm3mhPwvgiDHmoDEmC+CDAL54a7rl4eHh4XGjuGkburW2Y4z5MID/ByAE8Alr7Ss3ep79818AABibpG3ZDHXLBPK9abWaAIBO3KZjstl0X5zQb20iFh8TxACAIFR9bpdoH2hfJttI94Vw15RzxEkHANDuSN+ShC1NJuL+iOWpyfu0LSrhcRkjra0WjSGOo1VjD7hvrUTaqtQN1Fpx2la67wlofPjDH063O53OqmveCtzw+eyKv7op0G3UGrhGbbgzbv4SdbybZznJtby11uq3O/5jH/vYqn37f5TnNu6kbdNXrwAAmg1ZM4fuOgwA6OmuAAAyofQnm6GFl9VtvJ4jo9ZYpw4AKJcyfA7pa8TboVrEs7MzAICurq60LZPJ8HnpOBPIOTpJCwAQrCG6BUYaa1Uyh0YRrcl8Pp/ua7XoHB1+BgGgkC/wtaRvv/+7v7Ps/Hv2DqXb5YGj9LtQnttKVxkAsNiUdV1dmOb+0v1O1GKIeBCFKJe25UN+hannNn0AuSlO5PyuLVFt7hpu7HR9nss11o7h+2cC/V6I1ziOfpvLUX+zgfQblrZNVuavNn0cAPD1Z76/6lwbxWZIUVhrvwzgy5s5h4eHh4fHrcGmXui3Ai2WsqytSyNLpzmU0qYA9CWLIpa8tcTBX12TkcamkyoS+QJGLAGG3BSpc5iEpGZ0RApx0nKiztEyJLnEIX1hW3pfHPC55GttWMrPq75FLBkFEXU8brdVRzo8JDmHk0jDcH0LWRiG6+67VbhZiV/PRypHKSkycSKV5TFY2ec0JgORhuQsm5fQ10K5SPc2sPJ4NKvUlrSE2M9n6bylAh0Xqcu4tZNTi6yQ5fuuxtKM3XG0rrJqnbgpiiK5t07yD5SU7+Ymx1qrXibVWpuvKXDarYWcN+CLZVhKdVI/ALSbTR6fGgtLnbjGmkisSPmdsJfOlZFnOg5JQg8ySkKvL1Hf4ir3Q87XtHRcW0nGDZ5fJbSj1SYtKuBnol6Td4t7TvT4nMYcBPIcWqfZ8GRqi0CnE/Mxck1j3PtJ1kxvL405V+ji88s9S9y6zkk/4qUyNgsf+u/h4eGxQ+Bf6B4eHh47BFtucrFskoAVU4dlMsrEohImbVKBwgKbNZTa6qwNmpjIskrVsaLSJO1w2XFOdQIAY1cQcwAMEzg2FNWxHpNud2Wa1LNqS9SopSVqC62ctyvP5Jgi9SpFIpQKORpnErTSfUFqXpGxuxG0k/XNBNqE8IOqE7uR8y4zb7jjl+mmbpc2EdGcN9s0H5HWs2P6bWjWunayRtvGcK2xRGz2CpTZKxvStTKBtOUCNqe5fYrQbNbJNBOGisCL6L63m0KsBmATW4farJFHMmbTUjZTkOPdPKg15sjhmM2GOt5j+upVAMDwQK8cz+aVMCvXCvlabp6V5QcRH99UJLEjbNttaVuJwMq+mPsbq+cgNjTmfJf0o3//MP12fhYAUK4tpftaDXpHxGV5HpNuijzvysrcu+sGbJdtNeX5cg4U+bzcl3RK1Zpw69j9DZSNt8NjTvTy48tnI1m7hQITx3BmQzHpJM6cq2XqW+DE4CV0Dw8Pjx2CLZfQo5gl81C+jgFLGrlQff0d48RfykAzP/zTjpZgHcmTFelm14G7AQALc1MAgKlpkWQyEUnjAeTL3erQ9NStBEQdP08Sj831AwDaoZA8LZYcluZn0rZLEyxp5JXkNT4HANi3i67Z36WlOOfKKGN3wkdsV7tGOWjJ+Fa4K94SKT/tt9Ie2LWzo8SbNmtKp86cAQAM7xJ3t4TJ7cE+kTDzTCQlm+jjteYoy1J40hHJLmTpKqMIuQy3BTGto2xGSX0hu8Yq7SsT0L1NjNLIEnbHbTA5qtZTg8deLMoaDh1TqsVDnocqu1Q+99zz6a42awq9lTenbbkcOweoKUhdZ1l7DZS7oLHOOUDWpE0cMbi+hN6BuFYGoLWehIoQZi0tVNpaidnNSpHv8fPPpvtaUyStjzxwt/TtKj1zTSPzVuaBLdaJWM2rseRYYw/6hYAMmBTVr5Rmkc4btVlzactkLZbovuTm59O2aO99AIBaT3falrDWFfM9yydCrKYWgVjawnjz8rWX0D08PDx2CPwL3cPDw2OHYMtNLk4vN5Gk1XXqcEdHUDIB1WI1OKvIpjh26p8ySfA5tF/vW378JwAAz/39PwAALrPpBQCqHRf5KarY+bFJAMDZsUtpW653BACwZ/ggXTMnamWL1cVMWbJcdhqkJk5PSpqbYi+Za8aWKPqwodTn4S5SCYsZUUPjNqnNOhhuJR24Fil6OyJFr22aYfIto6J62ce8viQk+Nw8qcYTU2SqKnSJ+tzPEZE6qtGRgDp6dI3OrujFxpFl855V58i4yY+l3yEceU9tGeXX3XbqdiLnCCs0D8aquAP2d05cNHIs63ppgUxz5aKQgAHPt47ajDiyeo7J0JkFMSUW2E+7pSwjrTZdK8rqNUNtMUdid5S5yUVpZ5WPteU1m8TrmwH1zDsTYqDGHnd4rMrWYdgk0jB03zOJrAUzQKa42qL0rX32JPXXiFkq4emqOv929Xxl2xw/clGR8jwf2tGiwebTsMFzJZdEcxf1sX5FTKtdhp550z0g4+PrtgNHNKvYC57vUJHsUbB5M6eX0D08PDx2CLZcQm8G9CWer6kIMpZuessiVlSYZIpYQtGEVep2pAgaR5rWarNp29e+RHljJuZI4phYku/Z+Ut03PnLkuI9zJO0HoeVtK1UoS9xpkj7orxIBjmWIvOBjGWqRVFqI3v2pW0NJmvOnCEJfWZO5ZTZTec9MCiaQoZd94xyGxP5jMervv42uTGZNA3MXENA0FJ5sIaEHrMUlrA0oqNZXQTe1emFtG2hSmOt6/wdNRpNkCPyuVqXe1suskSq+ubk/Y0qIDeqqeSMc7GT+XZk6JouhwlHJiqXw4g1ykgxj6Gh+bCxvns8PnYEiJVr29IizdsFfc3IRVaLNLm3QvPmXBRfevnldN8b7r8fAJBol8qY5jevXXpZU6jXWAOO5Pwd1hDDSJwD2pwvqNlcPyV2rKT3hNew1TIkOzG0tHsjX7d7kedqcDjdVxjaT/2xQkaCXS/twK60qZ7h3CxXKC8MlAtwlZ9XO9yftmUS6lNDafgl1hJbizS+ps6xU+CI3Krcl6iftAeTUW6ZnK+li38aKg2gY2juTaBcdLH5aG8voXt4eHjsEPgXuoeHh8cOwZabXK7WSc2YaQsp+s2/+wYA4L6jYrr4sfuJbOhlf3VNxrgkPIFSX2ImXxSXhrPnyc95pk6qkC32pfvCMpNvfWIeKHD905ZKmdpiIq7SS32rlKWPk1fIhLIwq8gSVgnzBTHNXJglMjZTIXVyclyqS5WvLAIAdlXk+IJL1ZsoMm0FqjWd3IxVTqVqutTCoUr05LZdOlCVEwtBsvpb76JYta1jic0BjhwtKOKswRF148rkMjlL24kizNpsT6ktEoE8OSXzN3ZpHABw35FDadtdB/ZQ/5VffkrOukhfbWVx3dZhCtegSkM2+SVtMScEbOKrz8tYwOYGy0mdwoKMPcv3Kqvm27TJ1BZrMwVHQ5uUiBVzU7VKpoWJCTm+VCnzNVViMp7z1hIdl1f+8FfniFh9/vtihinl6JqHD8mcRmz6adZo/RUilUiqSWsrVmmkY/eoNdR8rISaYpfCNlkWK8L71LOcYXNX7vQpOv1z3073dd7MpiqVhtZyjEh2UZ6NBmgeyhzvEebk+KRE5zdWEfWcHK+rX95BmUtsrlmiNZkZFucHXKR9UUXMoo2rNL9hUdqSo+Sb3uDEXoEi8bMdmpxI2RLtNTj+jcJL6B4eHh47BNeV0I0xnwDwUwAmrbUPcFsfgD8HcADAOQA/Z62dXe8c1+xAN0kJtWn5trSzRDzO1FTy9xa5EVWy7OaliBQnkYahkDaNFkm4VxX/NLVIX+diDxEivYNCVFYTkjQGoKLymEBpZURqalRJgmks0fH7FblSY2l8siXSsmFpaX5GSWUsrdT56x9mpd8TCzSN4/OiFewfYA3kGl/wuboMtFwkrSFQeSVcsY5lgrcja1wQ7rK0tWt869dwh7wyTi6dfX2k7RTyIvk0GzTmYk7adg2SpmWV+Fat0VhLLMm0GirdKQ96qSnj66R5NpQbXeo+6fatGuYyifFa3pZ5V8BAHeQk9JzSCspMPnczmRWw+yUA5Pge57VAylpU0JC1kBY94EIprQVZa10l2tfbJ5rk2THSAs9cvJK2nTz9NABgdook0qWGnKPWppozEZQbIkv+D959NG17308+DgDYzeu5mZdxNqpV/p1cs8IF6E19EeshE8r6c+mvHTkKSArZSMmV5Vm6VmeM3HwrSttYvEzXb+UlGtOC3gvmymTaVhplQrPCmifkWSqwu2x2TvrdYCK6MzWetmV5DjsLNFe5GXGMaNdZmyqIhjN3lpwpsgWR0LtGiMR1qaCsclFsOjJcreFWsnkRfSMS+icBPL6i7SMAnrbWHgHwNP/fw8PDw2MLcV0J3Vr7LWPMgRXN7wfwTt7+FIBvAPj1m+nA3W94DAAw9syJtK3cTV//x972lrStGJKducUSspY+DWeji63k++gaovrVL758Ss7bQ9Lh7v3kymWVLS7DUnjSnE7bWq1k1bVC/qK+8tJLAICKSlBfLJFkUFJ2tMtXJgAszzMTstTRx+5mc7Ni/5udoe2z4+KaNTpMLllRVkU3rEBUEU0hZum6revvsW0y/Quxa7pgFS2R2jV8GJ0Arzwk0wAXl+8DynW0h12/2m11LpbaimWxSToJ3XCwmFEuYrmCc+9SZdWYGFlmc1zVN7lmZvkhvHt9Ef3iuXPcb5nvxQVad3FbNIVLl0g7meU1UF0Se/JQP0nV5ZIEBYVcnKWlMhRGnGso4FxCVSW9N9xgVKGNC5eJfzk7JjxDtUW/zXez61xJJsatxFJWZLfx8xSMc/nyRNr27W//HQDgXuYqBntEIq0vkeTvysMBQPteyqeyNL++Yp7Lytitk9YTpTKzhhMoN9slDgRcevSNAIBK9KZ0X22R7kFb5X0yOZ4bVZ4xU6DrVtk9U7vbtjlfSkY9G3WeG+00WGe7fm2JrlkqyFgafHyuLM95Xxe9e2L1rljitQt2oyy0VcZG7pP2MG7fgvxJN2tDH7bWjgMA/x26zvEeHh4eHj9g/MBJUWPMk8aYY8aYYzpPs4eHh4fHrcXNui1OGGNGrLXjxpgRAJPrHWitfQrAUwAwOjq6SqcodpOpYP8hIWjqbIHYd/Bw2jbAavvc2XMAgLaOLuuQ6eKxd/xM2rbv0KMAgIMPnkvbnnuBzCS9ZTJhXJ6UXC4RuzHldHEF7u1SVciuuRlSO/vKGX0I9YPNKgODksvFFW2YmhUTiuFoyi52eYxCRYywyv36xbG0bbCX1PIje5Tr1Ap84o//l5yf+5FR6l+5i1TGwweFCH7zG8itypW9tMos5EhGq+0rLseOMqs4wi6bo/NrsjObJRNKf69yn3S1YVWNxjRHSIbO0ejI+eeYJJ5TqUoX58kE0Naumkxk9rPr2ZHDQlhlXDShLgwfLDPALMO3//4ZHq4qsOKI7LqshXNXiLhLa38q8ai3m0wWJUUS5/i4jHJljNilLuCaojVFaEZ8DqvyFl2ZISK9rdjtYpdzt+N8R0vK3ZLvR6Mh/a500Xnf+qYH07Yqp3xusIvuhQtiSnn99ddp7MrF7vw0zX29JueNckLuA0CpJA4GHZ6HdqzvGReaUWSgYRNUYZiIz4WqjOXqPI3dKHfcFtdMzWpycY5+43JB5bLyHCzwGs9n1KvPpTVWkaJNjl4G1wyer8uadGl0iiqatmsPmXhDbQZM6+HyvdK1LNybQy3K5Bb4Ld6shP5FAE/w9hMAvrDpnnh4eHh4bAobcVv8MxABOmCMGQPwWwB+G8BnjDEfAnABwM/ebAfCHBELlyeOp20PvYmS8Ze65YsfLhIBFbOUEKnyWWcuEnHx9t6DcuIiBZ90lVSV9oiuVWA3wXxWlQrnr/Pu0ZG06VWWTLKK3FlgYubgXtIojt5zX7pvZoaLWVQkQOEyu1MZRcL09JJUO8/Sp85/UijSb+uL0u9TFzjYQxFbw5K6go6vqeCnOm1nVJDPIgu4RdUW33sPAKBhmTxSEnqOJSUt1bpCFToLYXcfaSMp8aTcHZ0bVqikcRfppWWRhKWVcxz4dWlSFL6ZadKI6nWR7OImS6Iq54vLKbJnLwVr7du7J91XSteKJn3Xl9BfPEX9KBZEI7KsETY7cl+6OWumI/9aSgq+ukT3IFRz1ZUnjawTCwlumAQM2bfNRBKolquSZNlqC9k6M+PIUF0ujf62OEfMYlXmqsXurHsHxfWxv5cWjwtcAoCZWcoD099D/Xj0jfen+8bYNXW+Lmv4tTG6L4Fa1wcl7QoAIFKZTgtd9MwtqZJyEas0scoyGHHwTcBrMlHuloYL3kTqmm6r3VIZJlnLjljy1hqRI0NjpQW60nYdtSozBSYt49VZW13ul0xHaQrsMaAzNuZjl6GTr6WWnAusW+5FvPnsqBvxcvn5dXa9e9NX9/Dw8PC4ZfCRoh4eHh47BFueyyWTJ4Km0dDqM9dvVBGUxZIjmcgUoOuNliNSmT751MfTtp/+Fx+mc6jotizXUnTFMg4e2p3um5whgquxJGrzriHyW9cFA5pc5/HQYSJs7zosZO78C1TLsbooaqUjdToqQq7OJpEerj8YW4la6+4ldbGjKhKEAY1v7LKYIobfgGX4uX/2z6WPTBaWVP4YR8IUlKnKpZZYWOD8Kh0xBWSYpIuU/61l1bWu/LNtQudzVdE1ERvx8ZmMjkBdbbZx/rcNzn9SUjkyejmfTtySvuVDGtfctJgMxi6dAwAcZiI9DJRpybqK9irF8DVcfhfYrGc18cixBYVQ5mPP3ruo/y5N8BVZa1NsKhoeFo/e3ACZgapz4s+dcCRsdy/ZK3I5iaVo8JBrHTG55Pk5iNuyxkImF13Rl0xWFdrI0/Zjj4gJ5ej+UTp/S9b62ddpXK+feBUA8LY3C2G6dy8df+FlyTnUjl1OpfVrimZVP7JcUzexYuYsMAneUWmKFzlSNmbiM98tpqLhEpvAFHno1rU2V4RwNVPpry7MsRYsP5va5BKzr7tLUxyoa2adoUclimryO0XnjorY5BiD88fooiv83Oi6rtr0erPwErqHh4fHDsGWS+iGI8hqSjJusISZ0XkcptmliPO1ZDCX7hvpoS/mqeMSFXp57DRt1KT02/mxcwCAh3dRdOru/cIsjk6ShFQ9LVJIX46kw64eKSv1+utn6ZqjJN3PLYj01OYv/cRVJYE5skS5JtZYQjec20FTISWXvTGRyM+sofloTV3BekjaIkGkEoraX87SeQt5mdM6Z8qrtakf586ck2syKbrv4P607exFmssv/fXTaVubM1zmOV9LUZ3fRdd1VyTqsKebpKyHHxYVY3CApNK79tCcBspd0ElZjrgChOyqD4n0NjpC92p0N5HaOoNfjV3blmks1xBlMkzUDw6Npm15JqSnpsSdtMpRyy7cr6EiQLsHaW3tVq63Xd00zsqASO3TTKTHLLG1VUU35yJZU0Riq+0IT9FYsi6jZ47uccaKBjXEcz/YK/cgzwTfYK+wmBV27Zu+cAEAcP71c+m+XX20/ucnnknbMkyGt8L1XyGRyl0SchbJvMrvMjdJBO/MkuRQuTpO89vbRev/gftEU8iwdt5UhHCbNQRN6Lv174q+BIqod1KyLp0Yp0SsZi2X5wbSmVyRnkOeuYiP12vX/SbjNCf9oPPpA+WCGV/DlXaj8BK6h4eHxw6Bf6F7eHh47BBsucklTX2r1JeRAVK3tPr+tZfJJ7yXk+wf6RMVKJ9jUigSX+yrk+fo9E2JeNt3F/mph3zeYkUIqIFhIqymZ0S9nWcyVBc2HxoidTlic1BDkZcu6VJdmQc6/OOOOkmjyak5O/Q97VcquOFag1kjY8kxaRTb5ZF4Gn/5f76SbiecsD9QPrxlJpi7lPnjwBEa82A/mRj6RySKtI/7lFfJpeaOkznqe8el7mrdumIa9P9IqcMV/u3hfWK2edtjj9C1SuLjXWK13Wm8LTWnHfatrs2Lia3NftyFovStp4fMDROcDG1KFckocMTi8C6Z52JRxSCsQC+b2EJlTmhyIQ+jZKCZaerTwgKnQVYmwpAjDM9fkgRYlQUyl3R3S5yC8z9vslOAUQRhzkUzluS+F6yLLNW5gOmZKBXYHGnFHLOnn+alqAjK6gL1u6NMOa74x0E2ER1/7Uy67+hRSsQFRYBevky+6fleMXsBens5CeiKrSTK/LHIMR1Xr4opcW6Wznvy5e8CAF576R/SfYcPU8zHgcP3pm29A2w2UuYKlyraFTvRhoww9WFXfUsLvUibq5ErhXQU6crHa149jaxeg21PSddlye/4rOp+63fJzcJL6B4eHh47BFsuobsoru6yEFY9XbRtVM6QBUuSxtQsfSkHuqTrJSZ04kAkk3OXzwEAhnslGf5+/sI7d7DvPifRqZfGSZLvKovUnmG3qldOX1A9dpGO9LepvqpLHKHXowoSdFjsHJ9QCfi7qE8Ru0YViyKBufwnaAuxGlepb8ND6+dyefaF76fbhQwRlM2mELZZJvXe8tY3p23nL5GkPc2c1AP3i2tblgnNWlOk/AxrNo88IoRmgyMRsyxNHjkk0br3c4rV0QGRSCtFureJclO9eIWiFCdnubjH1NV0X5XJ8rk5kdBbnMI2o1wwXS4ZF0ncVgRlsYfm7QHI+Lq7159LJ2nXVCRqaFwJP9EKYk7FGnEEcmJFPsrm6PwDAxJ5XOY1nleuoN3c74jvmXbntOwa2FHupN3s0hmo6MqE08RGLrqyKZJ3NyeQsR3RGmPWeloq0rHO96PIa/P8FVl/r75O2l+zKRGo7QbNrw019b4+nFSbz8vY77mbIpUP3yvuw7VFktZfeZ5cgF84JkTst79FGuLxV2WtH733IQDAkbtFau/ppfXmyOJwWR/d/K6Re1mTra5kXmd12UcXPRorEjVJ3SfXx7L01MaVzZQ1rFNs3yy8hO7h4eGxQ+Bf6B4eHh47BFtucnHRe7uGxCfc1RhMFLk4sodU+WNsSpkzkqLWhqSWdw8I8dhdYR/QvKjWB9jkUuaUvX/0iT9J99X4Wgt1IdNq7AesM23u4kjOxgypf9WcviaZhV47If7wExNkPlhQ0aM9PXTCSonU51CRWBmO3gtrl9K2wRLt786LQqeSkAIArl5U/vN9ZDbas0dIwPvecITOn5NzvPIiEU/DrAaXVTWjSa6vWKqIyaq/Qse97/F3pG0BO3R3d9NxA/3iPz/DqYbPnpf5mJ8jM9DCvETHLjL5PMdpimcWJAK0wwRvRqU1znKFoEBF1nVXaFw9HFnaq8xTOTZpZQti2lqqC+m8Ev3sQ659+8tcfSZR6V8zAc3HEPurGxUlm2WfaWcKAoA8R0uGKs+uM7GkVZqUycX54NeqsnZcxGJOLUrL5pfaPM33pXMy3zPs/NxTkOOHOcVwPq9r8LIJJSJzU1QU8vwq1/fcOyLPXBdX81pork/kJSotrkviZQPdRn0LlW96Tz+loX37O2ntHj4sJry//eY3AABnz8qzUX2Bn9sFMck9+AaqdrR3L51Lp6eOO7TGY9W3hE27y6p0pfVz3V/Z5ertaoLcWUu0z7sjSNNrLSNF+R2nzDbahHOz8BK6h4eHxw7BlkvojgSs9IqE3ompW7lI3MCOcmGGY8+R5LWQkQi8xJC0N7xbvvSvHid3px/60X+Vtv0DFy6oVklKbLekwMXkFeeKJ9+4Ja4BGKmovN6AJPjdBTrH/FWRhjohScbDQ0KsxuzqVVcSYaNOEmmVybdOIhJYu0GRckMZkQRHyyRJNTvStlJCv3TylXR7gYmzn/4n/zZte/xxSo75N18T98YhJguHihxFqlzh8hw9N9wtkloXb+eVu2CHpRonieqcNVdOkCR1YVJc91pcqCTKS5rYri4ikYdYYmy3VhNRGVWkwOW80LkvurpoLJVKF+9TdSo5n87EhNzvRmP96llFlk7birgtsAtmT0W0niRN5UyEZkHVSU1JLyUdJpbbtBzliou4v4qs6/D97sTS14VpGoN+cDMsoS/NkzY4flmio4f7aCw9JYl2rrF0nShNocNndETsbi7YAAB3c53Rh+6ToiEnz9Dz8sL3xLFgJXTK6IALUASRaN0ZdgqIVXSlSz8bMEl85KgQ8Am7+Y6Pfy5tm52isZ5qilY3cYnqE991hEjXe++XcwwNE0kdqXdLp83FN1RK3Zhr5Lr7uGZBlGU5ZVbvT1M08zzoU6TFZJTovywa9SbhJXQPDw+PHYKNFLjYC+CPAewC+fo8Za39fWNMH4A/B3AAwDkAP2egHt4UAAAgAElEQVStXb8E+DpwuUt6B0SC6PDXvBFIYYR8mSUNzlB44aIEI7z9zeSO1liSL2axi9wExy9J7o3TJ6naecdVA1feTFW223b1i5vZ/DxJRt1lkUjvPkq5JZ596TUAwPPHz0o/fuy9AJZniTxzmiT4OZWx0bk8Nuokme8fFsmuwEEkfX0iGduIJIdOa323poYqBfbgG6mP73r3u9K2/h6ybf/wW5T9myW7LtYUKmWRmkMu2uCq0gNiq9VFB+ZnyW5bYYknURlkDt39AABgaI9kpJyZJc2mq0dcGV3mPmNXV2R3dlhXGg0AltimbFXJMFc44eI42f6dFgQAbS7+ofO7FEvrBxZVWZvqUgUuXJDRpMrTs8DBTglnZTzsAnAA9HD+kzCjpU/a1lpMi+uZ1Zg7aTSl350WzZVRBTFsk44vKY2lp4c0nEKWbNyRkXXSw9pdd5esyRafo6aySbY4w2nAgS69SjMrcpbSMcXTsHCN++8+krZdVe6mdC7NB7C9XPUty7sT/SCy5OpszC2lre3ZewAAcODAgbTt2Qm63x1VHu/q5Bz3h6T348dfTve5wKm77pJ+Dw+T22RXl/BF4AC/Rott7urZy7BGpoOInNuijiuyRrtG0qjS06cFMQThLShwsREJvQPg16y19wJ4K4BfNsbcB+AjAJ621h4B8DT/38PDw8Nji3DdF7q1dtxa+zxvLwI4DmA3gPcD+BQf9ikAP7P2GTw8PDw8bgduiBQ1xhwA8DCA7wAYttaOA/TSN8YMXeOn6yLhGo3dfVLUoFonNacWi4riCDBXK/LkK8oVrkaqTbkkuUi49gDOnxQ18RKTRW97G6XP1WlJuzgdbt+ouEldmCGzSr2pktuXSL2tDBJp9HCX1K68yur4ufMvylhqZJ6Ym5drDQ2SatxtqT/7y+LqN1ThohBGTCguZWpJqbDi9Ec4dM9D6fYHf+nf0PhiUctPnCZiMjEqBw6Tp21W/2bmVNKaxOWxEfrVFVZPIMTW4gL1JJwg1fiyqgfqCpUkDSGbSkzAnjklprCznLLVuf31Dch8OPPA/LyQXtNTRAxaZUIJ2B3OBC6viYo8ZgI2r1MHL62klQU5dpGcnpKxvD5L13RRlgDQ00vk98gI5RNpqajCdovMNomVPi6wWayuzEExR3CGbM7StSudWSVfkrEU2F2xodZuwkRiqcxusGqdZDlKUhPIjmBuKBLQ8HGOlGyrIiZj02RJrakapI5U3DUi638lQmVySLfVNWF4vpa587nfmFX7XJRpV5eYg1KyclnxEmfCo2stzsp9fIFTUL/y0rNpW18/3cddu4QI3jVygK9JZph+ZYod5IK+RhHv7j53lBmww6Rp6raoXR/Z3GWV+c0mK000N44Nk6LGmDKAzwH4VWvtwvWOV7970hhzzBhzrFZb37PAw8PDw2Nz2JCEbigF4OcA/Km19vPcPGGMGWHpfATA5Fq/tdY+BeApABgdHV3F6i1yIpGCylSXZp5LVLk0JlMG+kh6OxlINrjJGZJ8pkP5wnWX6St6zwNCdJw5R5KgKyKgicojR4gkOXLwrrTt/DhJJK+88r20bXqKg1S4CEKvclUbe4Uk+vEp+d4ZJnZDFeA0spfcv/bzF3tfl0hgeS5l1WzowAeSqLRb1Up84Bf+Zbrdu4ukppe+L1KwI5daSgqImaRzpdY0KeNKe8VaguC2YJkYwLlTOAvm1LS4KDq3OxVLgp5KD/dHJN2ZadZGWEqcmhICtMnaSUe5fcZcBjBUuVyKeZrnnHNp1BXZXfIeiPRUUFkkV2KOid7Ll8T9r8Rk9T2q4ILLSFnk/DSNumhVs7Pk3tpuyzhrnGulqNw+uyu07ks5+ltQZGfEUmesSNFOp8XnVdk7XfmztBiDKprAWm5bPXlRyKReolxpOZvk9FXSRKamxcXTZUWcVfl0nKaV6xJtaiWM1RI6/dVEoWGpVuc4SSVt/usISACoL1E/rlyRghiXL9P2fFGOy/A6ciR/SeWPKUZ0nCbIL3FRjVPn5J1Sr1MRl05M5xoYlGInDz5IAYpHDotEPzhIa6HSLc4duQJpEhZ8ffXsddIkjoqYvh2kqKGckh8HcNxa+7tq1xcBPMHbTwD4wqZ74+Hh4eFx09iIhP7DAH4RwPeMMc44/B8B/DaAzxhjPgTgAoCf/cF00cPDw8NjI7juC91a+7dYPyvkuzfbgTOnSc3Zd0TSX+YDTgPaEuIqYrVJiBEhUctctOGee8QP+G++8mUAQG1e/NWL/URenR4j69DePUKiHrybCi/klBp/aB/tn5sR9/pXuW5pwoTL2KyQRwtM5jZiMR8tzJFZZ0gRLuenqa1vL5kfpnPKJzphElWZV2zEtRQTUd9XelG/8OKxdPvl79F310BMOS5fRqSLMKSpYDN8jKjqEafb1elOXT6VrOpvwH7qoaV9laxEyQZslmqHyjzAkbPKbRhZzrXSrrF/dFVMVi0mDU1bRY+yzaelSPOYo0Gri3R8Ud3HwW7qR6RMHc6ysRY12jdI66RXFR5xBRoiNR+LS0RMLi1Rf3M5MZc4UlGnXx0dJjI8lxfzgCNDLecTqTakRw0mnOdmJb/Q9Az5eteVeedeTlOcYd/+5QUduN6pWk9NroU6lkZHiw95i81Ztaqcf36OTI9ZFfXqxv70176Wtr3jLQ9jGVTxhsT5l3dUhCabZJQ7PExqDqJ9oYqcfen55wAAS7Pi797P/vUXx6Wtwj70WX5uEhVhXSmzP7yKD8hGXBgkp+IwAjbjzpKZ6dxZicSem6V5e/6Yyt3DcRt790o07SgXjBkZpWd/dFjeNyVO020Kqt5psH5sxEbhI0U9PDw8dgi2PJfLi6dJWt73wGNpWwL6OhpNAvIXfoEJmrk5IW36+8hl772P/1ja9tAbKY/DZz7/F2mb4bwM3Vx9ffeouFyVmawLOyKZ9O2i6Rk5KFLWPBcneP5FkoLHl5S7VIYI2O4RIYoGDlPbssII7CZ4got2nL4iEmyW2aO6ioys8jR0EpEq3rPCSfTb3/xqul3jzHPZjCpdVnSkrNzy0HL+DlclPaMldOpHPqcIW3b7y6osfVGJxprP0jhzKh+FSxViVJZIR263VeGMBhOeqVSrI+z4eF3aLg3xVRJxT4m2u0s0pnJBpOBchs6XMXIfjXI/XIk2k3TazTFil8p4GdHnyu/x/CnROM9SeL0q46xzhsm68jl1mlCQcW5ssuZPHH8VAHD+3Lm0zUU5W+UOOTpCDgB9nPGyrrzJ3PbcrBCa00z61pUG7HIOOU+0uQXRkgKe+2Ika8fli7lyRTTglRJ6WxXVcKS86cg5XFSqdtazoDZHoi4tyWS5Yip3HxVt/pGHHgUAPPeyFL145lnKIjrHxVHijtyDoREiN9/+9renbRHf53PnxcX5mWcoF9QD91EUeqVbnCsmeMwTE+IA4NburmFxbzx48ABdnx0Lqovi9ukcDDKRaAWNNXIY3Si8hO7h4eGxQ+Bf6B4eHh47BFtucjk5Tyr9VKxSj2ZIBQ9aSkVJXA0++js6IjaHH/khIjTzGVFDD+6nyM+f/MAH07bP/sVf0bWu0HnH50XZazROAwCyEJV3pk7bp8+LWglWi+wgmXR6h8X8kNYVVNGYCZsnEiMmAJeMap4jOfMZlYSMU9hWjUouxWSkTbRKtlw9Gx6U6LnxOhFEcSxqdoXrnEaqbwtTRPYuLlS5X6KaJk5dXit6TZlVMgW6DzZD13eJ1QAgYJtLUSUrc5Xp4/Zqcxo4CZTJiu0iz+RmQZk/+rpITd2rYgD2jJD/r+M9mw1R1QNL6ylSkX09FVp3Ncm1leLkSUoJe//996VtBTah6OkImH5MODpwQkXJumRvzboya7AJMVZmlUOHDwAABoeo/7rwQobNPD0qUZYjVHWZTOdD/toJShu7pApiuH06hiFhk1J1Ueaoxv2scTRrS5nEXDGNCxNCPLoar/E16mDaZRGg1m2kcFGeKogViSNS+VYVVL3dH3nnu3mX/MAVrzj6kJhsH3gT1c11ZVcDRRO7AiyHDkm8ScRzeuCIpNkd3UdEc4EjjruVycWNyxVwAcSsMjQoacBdsq+QTVWBYn9jdnBoKztdYtafy43CS+geHh4eOwRbLqGfmKNvyhf+VqIxH9pP0squrBAGRZYSRnbRF3BkQKSWuw4xuWlFqhjnvCqf+PRfpW3PvUgkk4tEXRZ4aR0pJeeIc3SNWBN97ArYYYK1EyjS0M2mKiXVaPF51Zc4YoI0ZGnMqlwnHaaIMupr7kqRtdrrR5LZtkj03SWSOBYVsdqOSWq7594H5DejJK1McnTgpIoOXOK8Ljpdg5MsbSznLUUkhdzzRkpLelmVlru6QBpAvSUSY50LS+io1By7UpZYE+lRuUsGuYL7yKhIPod3k1vhUE7E1CV2dZxht74wK/NXLBEJXlYRuf2cv+PyWSHCHNos3TeWRMMJHBmpRExXvCJm18RTp06m+xbnHTEtj5grAhIp8TrhkMGAI22hXDH7WavSZGuNUy7X6zKnFy+OLTtOBR/CsotnrSX3zEnX1SnRgDPcT1fyr6MiKavstthRrpISabm+VFlX2knILpiRVRG8/Lx2VARvh+fBnV+XsXMCf0dpOK4cXEvlUBndx/mYEk5Rm6giEvycn70grqD1lssDpAqmdB9cdv3ZeblmxBJ3qXJABuvyIc3LmC9PzPA5qOM5lQ7cBcCasqyPxuz6ZRE3Ci+he3h4eOwQ+Be6h4eHxw7BlptcllgN+ZvnRV09+TpFj77nTUJK3TVKqv3ZMxSp+Y43i+kgz6r6YkvUuc/8NaXHfP5VSbBUc1FqbPIIVKpSpxYFKrrNmUlipc412RTSZpXQKN/mJkdcajIoilbXvyxyIqEsXAXydBdiJhV1UqwOE4jZLqnyszIX2vRlScQVt0l1qyt1uHaREpP1qQrrg5xWNsNVcgoqi1Y9dBVYtF1qtZpdq5OZ5h1cNer+eyV51YULZM6YnpNI26Yj2xSZFjHRXWAWa0ARoD2lEl9Z7sGVKRrLiSlJ0mSY2KoMkRmpUBHCtMgkqk7LW1Yk10oU+J61lFnDkdXL6mQ6/3M2V1QqEr2cZ5/+cklIvZDHVVTRps7Eceo1Suw2PyOmgHmO6IyVz3kmyxGraj3lWH83PH81FW06ycRdrSnqfMhj6O2W9dRi81yNneQ7KvlXkppXdP5Xng+zvkz4rW99XcbSoapBpUjmI+Z111ZmFUfMu4Rk+llqs2lLP4+OcGw0pS1OK2BxKmpVP7Svh8y55bKumEVj0PyuScfnEp6piE4ec6BMKBEn/QrM6uPcEJaFVxh+fxTl+KDB5kJFeN8ovITu4eHhsUOw5RJ6/wDlt5iZlc/jOEe1/T3X7QSAuL2ft+hLOLhLojxNSF/g7x6TaLG/+hpFejUTkQjAX+ogWP0di1lytOoz7dzRtJTgojwzLBkY/TnlPBSa9HK1KHXumZCvH1qWOKzSFFjK12L7yC6SJrsqSqqsLZfQd430pdtjF8Z4TLqYAG2fPXkibZpnd0J39apyi6yyNJTEy5hjOl4VE2g1SaJ7/m+/AgB4Z0nG+QCPs94t0rIjAXUUcIMJu3mO3tTk7PnXKBpvqi6Ri40MXb8wJGPu3UUSV65CYwpVpGiR3f5yRSHZTbj+0neusXFH7oGLMk46SlvjsTtStKAiKQPWGusqJ0pzhrTFC7o4Bc+DSyHr8uUAQp5n8kor4Eu0WjJ/i7MkkTcaS/xXiGx3p/JqzbfrnIJX1X91BKb7q8lI517YUdqJZak2m1mfqM+rSOV2yPdFpcTOsdNBolxdndtmwNfUJHTC+W60VuAiZhOrooB51NbV7TSKhObbF6i6uFHIKaubEtmaEqQ8PF2ztM0as9a63Zox6tlY+Z5pqahXy+doqNdHLiRtanR0P24WXkL38PDw2CHYcgndSbMZlQWw0yDp6uyESGXNKgV7vOMRqiBf6JGcCfNcDOKb35GMg3W2/bZVtrscu4056WOtCkqhkhbSj62yreVYsjNOVArU8TmSQgqq/JlzcWqrQJpFltpcUEZTSYLdveyyOSKJ8svsD1lXgSArP8X7jkomtwV24auOTakjOOueckeb4etmecwtZS8Xu+1qt7RlBQkYp16m/BkXF0XyGQxoPpZpOCy1LCl7/RVLUuFptqmOqRwgtSJrOPukwMDwQZJg8j3iupreB5aaymXRFIpsTw/UGrPXsP0ucJ6g2qK4LU5epjXZaEjfXPk4l8dD32On6QUqmCnDgW+OVwEkw2XENnftothmO7LOB9Ns0tpZVO5x7raVKuwOqyRD26Z5bi7JWndFMuaVROokc2efNspentjVwWUut41J1i+6kqj7uFQlHqUY6ntAf2O1mF0AVIvdcDsd5crHhTysksYlq6U8hx22ocdOG1T32gVVaeHZWupns6Fz28TLjteau035nFi1uaBCXSRm+TXDlu43587p1YVvaHsUXkL38PDw+EcP/0L38PDw2CG4rsnFGJMH8C1QTYUIwGettb9ljDkI4NMA+gA8D+AXrVWhmhtESjJpYjAk1bGlSJuJJVKLnj9BxNJ7a6ICLVoyRVyaFZNEnlXuTk3O0WAV09WAjFQUn9u3zC3NOLcnOc4Gy1POZnLigrbErl4tlYLXmV+02cGZWKocsVruEfNKL+eCaKmUn6+xS1tGuWu9aYVWVukVgnBwmPKrjCuTS6r+qd802azi6k1q18D4GhGAy/bwidusslenJN9HkOOUxMpl7jJf40WIOn464vkokxpf2itFMgZHKSdPPxedAIAcuwK2VE8smwVyEVe5jzQx7doUaXkN37Ar58iFVldhdyq40RG/nL7XVX/X6naWzTs6j43brwnHDpsYlpa45mtT51xhlzmjXQhpXWRVMYbh3aN8DoroXJgVN9EOF6ywioR25pRaS5thnDnD+dhh1fEZNXZXeKJWU2bAFbh4UZwUTo1TP0qqRmjEtqJ4WUkOmlMXDZoooj7LuX50mzPRxDq1Ec+zIy2NypHiyFZt23L5YPR9ce61SeyiSBXZySbKZTmbXAEPuzqy1f2yrfJExX20LnY/KK7Z3e6WbiKly0Yk9CaAd1lr3wjgIQCPG2PeCuB3APyetfYIgFkAH7r5bnh4eHh4bBYbKUFnATg/qwz/swDeBcCVmv8UgP8E4GM33ANHNujCARz8kqi8Dy6fytlJkgg+8Zkvp/ve9U5Kcn/2skiHVRcsoL5ZGZepjqWEonI7ynLhivqiSNeOuLCKtMwwQekkQE2EOUkwUQRKnV3UdJs7roel6n6VFP/qNAWWzE1Jhse58xRMdfjQQayHQl4kthwHsGRUPpOYyTH98e+kkguPT++8hpSwjCJjaWiJx/eakvq6uTzdaw0pBPAKay/TFZFc+/fSuEYOkjTeo1wwc+wGGah8HG1eK2GkSrmxRBylQTZyfCpda5eya5CiYcKue8p1NHUv1OdlbS2wTmKTczTZBbPTlvXkJG5dcd7BkeeZrC4RyGUDNanMazGfU+5/BfrNzDRdU2dRzLDGGerq8qyNdrQ0uYLUWxZI4wp+KK1niYuo1KqSD2YlAqvKFzppNRap1mkDy4KTQnZbtM41UGlaLBmrOKt07q1yTXQ3woqPYgonhWvX4g5fv62cAhJ+B1lXIlA9D2leJtURg9VjsUx+dziAsaLyEe15kJw7IiP3e+4k57PaI9rojWJDNnRjTMgFoicBfBXA6wDmrIQRjgHYvc5vnzTGHDPGHFvLq8TDw8PD49ZgQy90a21srX0IwB4AjwG4d63D1vntU9baR621jxZVbmMPDw8Pj1uLG/JDt9bOGWO+AeCtAHqMMRFL6XsAXL7mj9dBP1cqb6iCBFWOZMuG4s/t0mo6X+JvfvfldN9Zrm84VxVmZGaJ1GbFLaLE6nuH1a6cql7vVPV8QeWJCJyPsKj2zme2wyYGo/1TWQWLVYX6FvvJFlT+Dpdkv2+ATC0tRQg3uaBDPSfXTDh6UFeEX4m2iuiscj6Orh65ZqNKarYuoBCzephmbFWpW81qq0AKq9IDWyaUquwj/G1VlOR8jdqmVb6KaJgqoI/sGUzbDg7Sdn83zUugok2rLCc0FLEVseqva37mOQo04urr+YIIDzmeex2FeS0ka+QRccqoVaYfy2xyatJR53CRhrE2GfA60uvOrTFH0i6zeiVuPQmpHDP53MrIva1zWltnakk0Acq5XxpKO3bjstoX2x3vzBWqHxGPxbaEyJ6dJjNau7X+muwoP/SYj2sFmhB2eX10URRu4mcpUPfApchNtGmEzWKJSjftCGln/dDHO5OZtvIkzj9cmdicmSk1zWj/cjYLQRO2zmyj3gdtTmPddzcV09h9YG+6r8H1SF9/TWJnCm22bEsQ/A3juhK6MWbQGNPD2wUAPw7gOICvA/gAH/YEgC/cfDc8PDw8PDaLjUjoIwA+ZSghQgDgM9baLxljXgXwaWPMfwbwAoCP30wHGix15tSnpckSUiYUKbXDH0qXsD8oiBR3jsnQQJE2HZaeOorQbHBGuSpHamrix0lNpaxIcQUmSgMlVTjCsVCk6+ucGlc5U16i3JMiJkR6K0Ja7uojrWTXLiL/5qoiySxwZsKleYlS7OFCB1NXdeTnADTaqop9mKWx9w7KNdtlmstOW2W2S9xfJkyVhO6GrCMGU+lNs3+OuONshG2VQ6XZTf2+q0dInt4+iu4sV2TplYt033JMODdUvpQWuzlaJV2Hzt1U94O3M6xpabdFV7xBE2z2Gqxvg139Iu2u6lzhtOsjj90VutDraaXkzR2grupITp575zYYq8jLNs9DqDSzNucDiZV7balJmo2TzHWunWadpfs1SsUla0T8un5Eer653zMTkj+ozRGr+hasgh4653wJsnLNjMt2Gi+ryME/5blSp7MuQ6HSEPOsgfRWhEh3JedcQRY9pyG7mOaUBuzytCyLjuX74iJnFxdUHhZenkkkczTPqRSjAenH/qNEfPZy9Pel106n+6ZOU0bZSPUtf428OBvFRrxcXgbw8BrtZ0D2dA8PDw+POwA+UtTDw8Njh2DLk3M5lTCnkhgVHTHSFlXTuZkm7AWtEwYlrJ51WorEil0KTU1s0XaSpuiU79nsDJk6ZtQ1K1wYoVtFYVbYdz0PMse46t0AELFKGKpal01O5uQKJOjjOjWu1VhTSYzmpnnswubmOSKxcY3oxlCpaz39ZA4ql5QfepNNUMrk0omdb7rzPVaJxvhbHyxLB8pmBJVcKmIVusgmjq4uFcHIRQTKOSG3S+ybns2JutrizSX2m68rgtcRt3ml3mZD57MtanOwwpyh73uLSa9sVpFYmfXn0kX/BsqskXGmPm0u4b65GVpWtD2NHFTJq+LVxLSLlHaFLlotue91NrXEdRXRyaRoSZmlCt2k0nd4nO2GnCNYwyaS+uNrgtyFg7ApqqRiNKpcG3ZhQcyAzmKl18xKhB01x1y3M1ERwhbU3xAqZTBvS1StIjSNXfYXABJOvleLJJGfRHu79Ndqvjmau9GWvrm1bpb5sqed5DOpUFS+via8K5zKefCoxIoE/K468ex36JqTYjIN+f7pQiVrmcBuFF5C9/Dw8NghMPYWfBU2itHRUfvkk0/etut5eHh47AR89KMffc5a++j1jvMSuoeHh8cOgX+he3h4eOwQ+Be6h4eHxw6Bf6F7eHh47BDcVlLUGHMVQBXA1PWOvcMxgO09hu3ef2D7j2G79x/Y/mPYTv3fb60dvN5Bt/WFDgDGmGMbYWvvZGz3MWz3/gPbfwzbvf/A9h/Ddu//WvAmFw8PD48dAv9C9/Dw8Ngh2IoX+lNbcM1bje0+hu3ef2D7j2G79x/Y/mPY7v1fhdtuQ/fw8PDw+MHAm1w8PDw8dghu6wvdGPO4MeaEMea0MeYjt/PaNwNjzF5jzNeNMceNMa8YY36F2/uMMV81xpziv71b3ddrgYt8v2CM+RL//6Ax5jvc/z83xmSvd46thDGmxxjzWWPMa3wv3rYN78G/5zX0fWPMnxlj8nfyfTDGfMIYM2mM+b5qW3PODeG/83P9sjHmka3ruWCdMfwXXkcvG2P+wlVj432/wWM4YYz5p1vT683htr3QueLRHwB4D4D7APy8Mea+23X9m0QHwK9Za+8F1VH9Ze7zRwA8ba09AuBp/v+djF8BlQ10+B0Av8f9nwXwoS3p1cbx+wD+2lp7D4A3gsaybe6BMWY3gH8H4FFr7QOgWj4fxJ19Hz4J4PEVbevN+XsAHOF/TwL42G3q4/XwSawew1cBPGCtfQOAkwB+AwD4uf4ggPv5N//DLMunuz1wOyX0xwCcttaesda2AHwawPtv4/VvGNbacWvt87y9CHqR7Ab1+1N82KcA/MzW9PD6MMbsAfCTAP6Q/28AvAvAZ/mQO73/FQDvAJc4tNa2rLVz2Eb3gBEBKBhjIgBFAOO4g++DtfZbAGZWNK835+8H8MeW8AyogPzI7enp+lhrDNbar1hJUv8MpCTz+wF82lrbtNaeBXAa27Ai2+18oe8GcFH9f4zbtgWMMQdApfi+A2DYWjsO0EsfwNDW9ey6+G8A/gMAl+W/H8CcWtR3+n04BOAqgD9is9EfGmNK2Eb3wFp7CcB/BXAB9CKfB/Acttd9ANaf8+36bP9rAP+Xt7frGJbhdr7Q16qAui1cbIwxZQCfA/Cr1tqF6x1/p8AY81MAJq21z+nmNQ69k+9DBOARAB+z1j4MSh1xx5pX1gLbmt8P4CCAUQAlkJliJe7k+3AtbLc1BWPMb4JMqn/qmtY47I4ew1q4nS/0MQB71f/3ALh8G69/UzDGZEAv8z+11n6emyecSsl/J9f7/RbjhwG8zxhzDmTiehdIYu9h1R+48+/DGIAxa+13+P+fBb3gt8s9AIAfB3DWWnvVWtsG8HkAP4TtdR+A9ed8Wz3bxpgnAPwUgF+w4re9raMrqJEAAAF9SURBVMawHm7nC/1ZAEeY2c+CCIgv3sbr3zDY3vxxAMettb+rdn0RwBO8/QSAL9zuvm0E1trfsNbusdYeAM3316y1vwDg6wA+wIfdsf0HAGvtFQAXjTF3c9O7AbyKbXIPGBcAvNUYU+Q15cawbe4DY705/yKAX2Jvl7cCmHemmTsNxpjHAfw6gPdZa2tq1xcBfNAYkzPGHAQRvN/dij5uCtba2/YPwHtBzPLrAH7zdl77Jvv7dpDa9TKAF/nfe0F26KcBnOK/fVvd1w2M5Z0AvsTbh0CL9TSA/w0gt9X9u07fHwJwjO/DXwLo3W73AMBHAbwG4PsA/gRA7k6+DwD+DGTvb4Ok1w+tN+cgc8Uf8HP9PZA3z506htMgW7l7nv+nOv43eQwnALxnq/t/M/98pKiHh4fHDoGPFPXw8PDYIfAvdA8PD48dAv9C9/Dw8Ngh8C90Dw8Pjx0C/0L38PDw2CHwL3QPDw+PHQL/Qvfw8PDYIfAvdA8PD48dgv8P8QITwTAXGKoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2871dc8cb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在看看神经网络认为上面这些例子是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出是10类的概率。 一个类的概率越高，网络认为图像是这个类的越多。 那么，让我们得到最高概率的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship  ship  ship\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络在整个测试集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 57 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来好于运气--10％的准确性（从10个类中随机挑选一个类）。 似乎网络学到了一些东西  \n",
    "下面看哪些类分的好，哪些类分的不好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 60 %\n",
      "Accuracy of   car : 72 %\n",
      "Accuracy of  bird : 39 %\n",
      "Accuracy of   cat : 35 %\n",
      "Accuracy of  deer : 47 %\n",
      "Accuracy of   dog : 47 %\n",
      "Accuracy of  frog : 70 %\n",
      "Accuracy of horse : 67 %\n",
      "Accuracy of  ship : 74 %\n",
      "Accuracy of truck : 62 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在GPU上训练\n",
    "就像将Tensor转移到GPU上一样，将神经网络转移到GPU上。  \n",
    "首先定义可用的CUDA设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这些方法将遍历所有模块，将他们的参数和缓存转移到CUDA设备  \n",
    "记得每一步的输入和label也要转移到GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "inputs, labels = inputs.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习：尝试增加网络的宽度（第一个nn.Conv2d的参数2和第二个nn.Conv2d的参数1  - 它们需要是相同的数字），看看你获得了什么样的加速"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据并行-使用多GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 DataParallel使用多 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型放在GPU上\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "# 将tensor放在GPU上\n",
    "mytensor = my_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，调用my_tensor.to（device）是在GPU上返回my_tensor的新副本，而不是重写my_tensor。 您需要将其分配给新的张量并在GPU上使用该张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在多个GPU上执行前向/反向传播是很自然的。 但是Pytorch默认只使用一个GPU。 通过使用DataParallel使模型并行运行，可以在多个GPU上运行操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Parameters and DataLoaders\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 30\n",
    "data_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成一个假数据集，只需实现__getitem__\n",
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单模型示例：input-linear-output   \n",
    "在模型中放置了一个print语句来监视输入和输出张量的大小。 请注意第0批次打印的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Our model\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\"\\tIn Model: input size\", input.size(),\n",
    "              \"output size\", output.size())\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本教程的**核心**部分：  \n",
    "首先，需要创建一个模型实例并检查我们是否有多个GPU。 如果有多个GPU，可以使用nn.DataParallel包装我们的模型。 然后通过model.to(device)将模型放在GPU上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "# Let's use 2 GPUs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "\tIn Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
      "Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "# input and output tensors的size\n",
    "for data in rand_loader:\n",
    "    input = data.to(device)\n",
    "    output = model(input)\n",
    "    print(\"Outside: input size\", input.size(), \"output_size\", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您没有GPU或一个GPU，当我们执行30批量输入和输出时，将获得30个In Model和30个outputs 。 但是如果你有多个GPU，那么可以得到下面的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on 2 GPUs\n",
    "# Let's use 2 GPUs!\n",
    "#     In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "#     In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "# Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "#     In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "#     In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "# Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "#     In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "#     In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n",
    "# Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
    "#     In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n",
    "#     In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n",
    "# Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataParallel自动拆分数据并将任务指令发送到多个GPU上的多个模型。 在每个模型完成其任务后，DataParallel会在结果返回给您前收集和合并结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
